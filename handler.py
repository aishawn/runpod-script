import runpod
from runpod.serverless.utils import rp_upload
import os
import websocket
import base64
import json
import uuid
import logging
import urllib.request
import urllib.parse
import binascii # Base64 ì—ëŸ¬ ì²˜ë¦¬ë¥¼ ìœ„í•´ import
import subprocess
import time
# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


server_address = os.getenv('SERVER_ADDRESS', '127.0.0.1')
client_id = str(uuid.uuid4())
def to_nearest_multiple_of_16(value):
    """ì£¼ì–´ì§„ ê°’ì„ ê°€ì¥ ê°€ê¹Œìš´ 16ì˜ ë°°ìˆ˜ë¡œ ë³´ì •, ìµœì†Œ 16 ë³´ì¥"""
    try:
        numeric_value = float(value)
    except Exception:
        raise Exception(f"width/height ê°’ì´ ìˆ«ìê°€ ì•„ë‹™ë‹ˆë‹¤: {value}")
    adjusted = int(round(numeric_value / 16.0) * 16)
    if adjusted < 16:
        adjusted = 16
    return adjusted
def process_input(input_data, temp_dir, output_filename, input_type):
    """ì…ë ¥ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ì—¬ íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    if input_type == "path":
        # ê²½ë¡œì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
        logger.info(f"ğŸ“ ê²½ë¡œ ì…ë ¥ ì²˜ë¦¬: {input_data}")
        return input_data
    elif input_type == "url":
        # URLì¸ ê²½ìš° ë‹¤ìš´ë¡œë“œ
        logger.info(f"ğŸŒ URL ì…ë ¥ ì²˜ë¦¬: {input_data}")
        os.makedirs(temp_dir, exist_ok=True)
        file_path = os.path.abspath(os.path.join(temp_dir, output_filename))
        return download_file_from_url(input_data, file_path)
    elif input_type == "base64":
        # Base64ì¸ ê²½ìš° ë””ì½”ë”©í•˜ì—¬ ì €ì¥
        logger.info(f"ğŸ”¢ Base64 ì…ë ¥ ì²˜ë¦¬")
        return save_base64_to_file(input_data, temp_dir, output_filename)
    else:
        raise Exception(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì…ë ¥ íƒ€ì…: {input_type}")

        
def download_file_from_url(url, output_path):
    """URLì—ì„œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    try:
        # wgetì„ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        result = subprocess.run([
            'wget', '-O', output_path, '--no-verbose', url
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            logger.info(f"âœ… URLì—ì„œ íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí–ˆìŠµë‹ˆë‹¤: {url} -> {output_path}")
            return output_path
        else:
            logger.error(f"âŒ wget ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {result.stderr}")
            raise Exception(f"URL ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {result.stderr}")
    except subprocess.TimeoutExpired:
        logger.error("âŒ ë‹¤ìš´ë¡œë“œ ì‹œê°„ ì´ˆê³¼")
        raise Exception("ë‹¤ìš´ë¡œë“œ ì‹œê°„ ì´ˆê³¼")
    except Exception as e:
        logger.error(f"âŒ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise Exception(f"ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


def save_base64_to_file(base64_data, temp_dir, output_filename):
    """Base64 ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # Base64 ë¬¸ìì—´ ë””ì½”ë”©
        decoded_data = base64.b64decode(base64_data)
        
        # ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
        os.makedirs(temp_dir, exist_ok=True)
        
        # íŒŒì¼ë¡œ ì €ì¥
        file_path = os.path.abspath(os.path.join(temp_dir, output_filename))
        with open(file_path, 'wb') as f:
            f.write(decoded_data)
        
        logger.info(f"âœ… Base64 ì…ë ¥ì„ '{file_path}' íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        return file_path
    except (binascii.Error, ValueError) as e:
        logger.error(f"âŒ Base64 ë””ì½”ë”© ì‹¤íŒ¨: {e}")
        raise Exception(f"Base64 ë””ì½”ë”© ì‹¤íŒ¨: {e}")
    
def queue_prompt(prompt, is_mega_model=False):
    url = f"http://{server_address}:8188/prompt"
    logger.info(f"Queueing prompt to: {url}")
    
    # è°ƒè¯•ï¼šæ£€æŸ¥å…³é”®èŠ‚ç‚¹çš„é…ç½®ï¼ˆå‘é€å‰æœ€åéªŒè¯ï¼‰
    logger.info("å‘é€promptå‰çš„æœ€åéªŒè¯:")
    if is_mega_model:
        # Rapid-AIO-Mega.json éªŒè¯
        if "16" in prompt and "widgets_values" in prompt["16"]:
            image_path_check = prompt["16"]["widgets_values"][0] if prompt["16"]["widgets_values"] else None
            logger.info(f"  èŠ‚ç‚¹16çš„image = {image_path_check}")
        if "28" in prompt and "widgets_values" in prompt["28"]:
            widgets = prompt["28"]["widgets_values"]
            logger.info(f"  èŠ‚ç‚¹28çš„strength = {widgets[3]} (I2V mode)")
    else:
        # æ ‡å‡† workflow éªŒè¯
        if "541" in prompt and "inputs" in prompt["541"]:
            fun_or_fl2v = prompt["541"]["inputs"].get("fun_or_fl2v_model")
            logger.info(f"  èŠ‚ç‚¹541çš„fun_or_fl2v_model = {fun_or_fl2v} (ç±»å‹: {type(fun_or_fl2v).__name__})")
        if "244" in prompt and "inputs" in prompt["244"]:
            image_path_check = prompt["244"]["inputs"].get("image")
            logger.info(f"  èŠ‚ç‚¹244çš„image = {image_path_check}")
    
    p = {"prompt": prompt, "client_id": client_id}
    data = json.dumps(p).encode('utf-8')
    req = urllib.request.Request(url, data=data)
    req.add_header('Content-Type', 'application/json')
    try:
        response = urllib.request.urlopen(req)
        return json.loads(response.read())
    except urllib.error.HTTPError as e:
        error_body = e.read().decode('utf-8')
        logger.error(f"HTTP Error {e.code}: {e.reason}")
        logger.error(f"Error response: {error_body}")
        try:
            error_json = json.loads(error_body)
            logger.error(f"Error details: {json.dumps(error_json, indent=2)}")
        except:
            pass
        raise Exception(f"ComfyUI API é”™è¯¯ ({e.code}): {error_body}")

def get_image(filename, subfolder, folder_type):
    url = f"http://{server_address}:8188/view"
    logger.info(f"Getting image from: {url}")
    data = {"filename": filename, "subfolder": subfolder, "type": folder_type}
    url_values = urllib.parse.urlencode(data)
    with urllib.request.urlopen(f"{url}?{url_values}") as response:
        return response.read()

def get_history(prompt_id):
    url = f"http://{server_address}:8188/history/{prompt_id}"
    logger.info(f"Getting history from: {url}")
    with urllib.request.urlopen(url) as response:
        return json.loads(response.read())

def get_videos(ws, prompt, is_mega_model=False):
    prompt_id = queue_prompt(prompt, is_mega_model)['prompt_id']
    output_videos = {}
    error_info = None
    
    while True:
        out = ws.recv()
        if isinstance(out, str):
            message = json.loads(out)
            if message['type'] == 'executing':
                data = message['data']
                if data['node'] is None and data['prompt_id'] == prompt_id:
                    break
            elif message['type'] == 'execution_error':
                # æ•è·æ‰§è¡Œé”™è¯¯
                error_info = message.get('data', {}).get('error', 'Unknown execution error')
                logger.error(f"Execution error received: {error_info}")
        else:
            continue

    history = get_history(prompt_id)[prompt_id]
    
    # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯ä¿¡æ¯
    if 'error' in history:
        error_info = history['error']
        if isinstance(error_info, dict):
            error_info = error_info.get('message', str(error_info))
        logger.error(f"Error in history: {error_info}")
        raise Exception(f"ComfyUI execution error: {error_info}")
    
    # æ£€æŸ¥ outputs æ˜¯å¦å­˜åœ¨
    if 'outputs' not in history:
        if error_info:
            raise Exception(f"ComfyUI execution error: {error_info}")
        raise Exception("No outputs found in execution history")
    
    for node_id in history['outputs']:
        node_output = history['outputs'][node_id]
        videos_output = []
        # æ”¯æŒå¤šç§è§†é¢‘è¾“å‡ºæ ¼å¼ï¼šgifs (æ ‡å‡† workflow) å’Œ videos (VHS_VideoCombine)
        video_list = None
        if 'gifs' in node_output:
            video_list = node_output['gifs']
        elif 'videos' in node_output:
            video_list = node_output['videos']
        
        if video_list:
            for video in video_list:
                # fullpathë¥¼ ì´ìš©í•˜ì—¬ ì§ì ‘ íŒŒì¼ì„ ì½ê³  base64ë¡œ ì¸ì½”ë”©
                if 'fullpath' in video:
                    with open(video['fullpath'], 'rb') as f:
                        video_data = base64.b64encode(f.read()).decode('utf-8')
                    videos_output.append(video_data)
                elif 'filename' in video:
                    # å¦‚æœæ²¡æœ‰ fullpathï¼Œå°è¯•ä½¿ç”¨ filename å’Œ subfolder
                    subfolder = video.get('subfolder', '')
                    folder_type = video.get('type', 'output')
                    filename = video['filename']
                    try:
                        video_bytes = get_image(filename, subfolder, folder_type)
                        video_data = base64.b64encode(video_bytes).decode('utf-8')
                        videos_output.append(video_data)
                    except Exception as e:
                        logger.warning(f"æ— æ³•è¯»å–è§†é¢‘æ–‡ä»¶ {filename}: {e}")
        output_videos[node_id] = videos_output

    return output_videos

def get_available_models():
    """è·å– ComfyUI ä¸­å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
    try:
        url = f"http://{server_address}:8188/object_info"
        with urllib.request.urlopen(url, timeout=5) as response:
            object_info = json.loads(response.read())
            models = []
            
            # é¦–å…ˆå°è¯• WanVideoModelLoaderï¼ˆç”¨äºæ ‡å‡† workflowï¼‰
            if "WanVideoModelLoader" in object_info:
                loader_info = object_info["WanVideoModelLoader"]
                # å°è¯•ä¸åŒçš„è¿”å›æ ¼å¼
                if "model" in loader_info:
                    models = loader_info["model"]
                elif "input" in loader_info and "required" in loader_info["input"]:
                    if "model" in loader_info["input"]["required"]:
                        models = loader_info["input"]["required"]["model"]
                
                # å¤„ç†åµŒå¥—åˆ—è¡¨çš„æƒ…å†µ
                if models and isinstance(models, list) and len(models) > 0:
                    if isinstance(models[0], list):
                        models = models[0]
                    models = [m for m in models if isinstance(m, str)]
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯• CheckpointLoaderSimpleï¼ˆç”¨äº Rapid-AIO-Mega.jsonï¼‰
            if not models and "CheckpointLoaderSimple" in object_info:
                loader_info = object_info["CheckpointLoaderSimple"]
                if "ckpt_name" in loader_info:
                    models = loader_info["ckpt_name"]
                elif "input" in loader_info and "required" in loader_info["input"]:
                    if "ckpt_name" in loader_info["input"]["required"]:
                        models = loader_info["input"]["required"]["ckpt_name"]
                
                # å¤„ç†åµŒå¥—åˆ—è¡¨çš„æƒ…å†µ
                if models and isinstance(models, list) and len(models) > 0:
                    if isinstance(models[0], list):
                        models = models[0]
                    models = [m for m in models if isinstance(m, str)]
            
            if models:
                logger.info(f"å¯ç”¨æ¨¡å‹åˆ—è¡¨: {models}")
            return models if models else []
    except Exception as e:
        logger.warning(f"è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
        return []

def update_model_in_prompt(prompt, node_id, available_models):
    """æ›´æ–° prompt ä¸­æŒ‡å®šèŠ‚ç‚¹çš„æ¨¡å‹åç§°ï¼Œå¦‚æœæ¨¡å‹ä¸å­˜åœ¨åˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹"""
    if node_id not in prompt:
        return False
    
    node = prompt[node_id]
    if "inputs" not in node or "model" not in node["inputs"]:
        return False
    
    current_model = node["inputs"]["model"]
    logger.info(f"èŠ‚ç‚¹ {node_id} é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹: {current_model}")
    
    # å¦‚æœå½“å‰æ¨¡å‹åœ¨å¯ç”¨åˆ—è¡¨ä¸­ï¼Œä¸éœ€è¦æ›´æ–°
    if current_model in available_models:
        logger.info(f"èŠ‚ç‚¹ {node_id} ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹: {current_model}")
        return False
    
    # ä¼˜å…ˆé€‰æ‹© I2V ç›¸å…³çš„æ¨¡å‹ï¼ˆåŒ…å« I2V å…³é”®å­—ï¼‰
    i2v_models = [m for m in available_models if "I2V" in m.upper() or "i2v" in m.lower()]
    if i2v_models:
        new_model = i2v_models[0]
        logger.info(f"èŠ‚ç‚¹ {node_id} æ¨¡å‹æ›´æ–°: {current_model} -> {new_model} (é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹ä¸åœ¨å¯ç”¨åˆ—è¡¨ä¸­ï¼Œå·²è‡ªåŠ¨æ›¿æ¢ä¸º I2V æ¨¡å‹)")
        node["inputs"]["model"] = new_model
        return True
    
    # å¦‚æœæ²¡æœ‰ I2V æ¨¡å‹ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹
    if available_models:
        new_model = available_models[0]
        logger.info(f"èŠ‚ç‚¹ {node_id} æ¨¡å‹æ›´æ–°: {current_model} -> {new_model} (é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹ä¸åœ¨å¯ç”¨åˆ—è¡¨ä¸­ï¼Œå·²è‡ªåŠ¨æ›¿æ¢ä¸ºç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹)")
        node["inputs"]["model"] = new_model
        return True
    
    return False

def load_workflow(workflow_path):
    """åŠ è½½å¹¶éªŒè¯å·¥ä½œæµJSONæ–‡ä»¶"""
    if not os.path.exists(workflow_path):
        raise FileNotFoundError(f"å·¥ä½œæµæ–‡ä»¶ä¸å­˜åœ¨: {workflow_path}")
    
    file_size = os.path.getsize(workflow_path)
    logger.info(f"åŠ è½½å·¥ä½œæµæ–‡ä»¶: {workflow_path} (å¤§å°: {file_size} å­—èŠ‚)")
    
    if file_size == 0:
        raise ValueError(f"å·¥ä½œæµæ–‡ä»¶ä¸ºç©º: {workflow_path}")
    
    try:
        with open(workflow_path, 'r', encoding='utf-8') as file:
            content = file.read()
            # æ£€æŸ¥æ–‡ä»¶å†…å®¹æ˜¯å¦çœ‹èµ·æ¥åƒJSONï¼ˆä»¥{æˆ–[å¼€å¤´ï¼‰
            content_stripped = content.strip()
            if not content_stripped.startswith(('{', '[')):
                # æ˜¾ç¤ºå‰500ä¸ªå­—ç¬¦ä»¥ä¾¿è°ƒè¯•
                preview = content[:500] if len(content) > 500 else content
                logger.error(f"æ–‡ä»¶å†…å®¹ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚å‰500å­—ç¬¦: {preview}")
                raise ValueError(f"å·¥ä½œæµæ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼: {workflow_path}")
            
            return json.loads(content)
    except json.JSONDecodeError as e:
        # æ˜¾ç¤ºé”™è¯¯ä½ç½®é™„è¿‘çš„å†…å®¹
        with open(workflow_path, 'r', encoding='utf-8') as file:
            lines = file.readlines()
            error_line = e.lineno - 1 if e.lineno > 0 else 0
            start_line = max(0, error_line - 2)
            end_line = min(len(lines), error_line + 3)
            context = ''.join(lines[start_line:end_line])
            logger.error(f"JSONè§£æé”™è¯¯ (è¡Œ {e.lineno}, åˆ— {e.colno}):\n{context}")
        raise ValueError(f"å·¥ä½œæµæ–‡ä»¶JSONæ ¼å¼é”™è¯¯: {workflow_path} - {str(e)}")
    except Exception as e:
        logger.error(f"åŠ è½½å·¥ä½œæµæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {workflow_path} - {str(e)}")
        raise

def handler(job):
    job_input = job.get("input", {})

    # è®°å½•job_inputï¼Œä½†æ’é™¤base64æ•°æ®ä»¥é¿å…æ—¥å¿—è¿‡é•¿
    log_input = {k: v for k, v in job_input.items() if k not in ["image_base64", "end_image_base64"]}
    if "image_base64" in job_input:
        log_input["image_base64"] = f"<base64 data, length: {len(job_input['image_base64'])}>"
    if "end_image_base64" in job_input:
        log_input["end_image_base64"] = f"<base64 data, length: {len(job_input['end_image_base64'])}>"
    logger.info(f"Received job input: {log_input}")
    task_id = f"task_{uuid.uuid4()}"

    # ì´ë¯¸ì§€ ì…ë ¥ ì²˜ë¦¬ (image_path, image_url, image_base64 ì¤‘ í•˜ë‚˜ë§Œ ì‚¬ìš©)
    image_path = None
    if "image_path" in job_input:
        image_path = process_input(job_input["image_path"], task_id, "input_image.jpg", "path")
    elif "image_url" in job_input:
        image_path = process_input(job_input["image_url"], task_id, "input_image.jpg", "url")
    elif "image_base64" in job_input:
        image_path = process_input(job_input["image_base64"], task_id, "input_image.jpg", "base64")
    else:
        # ê¸°ë³¸ê°’ ì‚¬ìš©
        image_path = "/example_image.png"
        logger.info("ê¸°ë³¸ ì´ë¯¸ì§€ íŒŒì¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤: /example_image.png")

    # ì—”ë“œ ì´ë¯¸ì§€ ì…ë ¥ ì²˜ë¦¬ (end_image_path, end_image_url, end_image_base64 ì¤‘ í•˜ë‚˜ë§Œ ì‚¬ìš©)
    end_image_path_local = None
    if "end_image_path" in job_input:
        end_image_path_local = process_input(job_input["end_image_path"], task_id, "end_image.jpg", "path")
    elif "end_image_url" in job_input:
        end_image_path_local = process_input(job_input["end_image_url"], task_id, "end_image.jpg", "url")
    elif "end_image_base64" in job_input:
        end_image_path_local = process_input(job_input["end_image_base64"], task_id, "end_image.jpg", "base64")
    
    # LoRA ì„¤ì • í™•ì¸ - ë°°ì—´ë¡œ ë°›ì•„ì„œ ì²˜ë¦¬
    lora_pairs = job_input.get("lora_pairs", [])
    
    # ìµœëŒ€ 4ê°œ LoRAê¹Œì§€ ì§€ì›
    lora_count = min(len(lora_pairs), 4)
    if lora_count > len(lora_pairs):
        logger.warning(f"LoRA ê°œìˆ˜ê°€ {len(lora_pairs)}ê°œì…ë‹ˆë‹¤. ìµœëŒ€ 4ê°œê¹Œì§€ë§Œ ì§€ì›ë©ë‹ˆë‹¤. ì²˜ìŒ 4ê°œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        lora_pairs = lora_pairs[:4]
    
    # è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼Œç”¨äºæ£€æµ‹ MEGA/AIO æ¨¡å‹
    available_models = get_available_models()
    
    # æ£€æµ‹æ˜¯å¦ä¸º MEGA/AIO æ¨¡å‹ï¼ˆæ”¯æŒ I2V å’Œ T2V çš„ all-in-one æ¨¡å‹ï¼‰
    is_mega_model = False
    if available_models:
        for model_name in available_models:
            model_name_lower = model_name.lower()
            if "mega" in model_name_lower or "aio" in model_name_lower or "all-in-one" in model_name_lower or "allinone" in model_name_lower:
                is_mega_model = True
                logger.info(f"æ£€æµ‹åˆ° MEGA/AIO æ¨¡å‹: {model_name}, å°†ä½¿ç”¨ Rapid-AIO-Mega workflow")
                break
    
    # ì›Œí¬í”Œë¡œìš° íŒŒì¼ ì„ íƒ
    # MEGA/AIO æ¨¡å‹ä½¿ç”¨ Rapid-AIO-Mega.jsonï¼Œå¦åˆ™ä½¿ç”¨æ ‡å‡† workflow
    if is_mega_model:
        workflow_file = "/Rapid-AIO-Mega.json"
        logger.info(f"Using Rapid-AIO-Mega workflow for MEGA/AIO model")
    else:
        workflow_file = "/new_Wan22_flf2v_api.json" if end_image_path_local else "/new_Wan22_api.json"
        logger.info(f"Using {'FLF2V' if end_image_path_local else 'single'} workflow with {lora_count} LoRA pairs")
    
    workflow_data = load_workflow(workflow_file)
    
    # è½¬æ¢ workflow æ ¼å¼ï¼šå¦‚æœä½¿ç”¨ nodes æ•°ç»„æ ¼å¼ï¼Œè½¬æ¢ä¸ºèŠ‚ç‚¹ ID key æ ¼å¼
    if "nodes" in workflow_data:
        # Rapid-AIO-Mega.json ä½¿ç”¨ nodes æ•°ç»„æ ¼å¼ï¼Œéœ€è¦è½¬æ¢
        prompt = {}
        for node in workflow_data["nodes"]:
            node_id = str(node["id"])
            # åˆ›å»ºç¬¦åˆ ComfyUI API æ ¼å¼çš„èŠ‚ç‚¹å¯¹è±¡
            converted_node = {}
            # å¤åˆ¶æ‰€æœ‰å­—æ®µ
            for key, value in node.items():
                if key != "id":  # æ’é™¤ id å­—æ®µ
                    converted_node[key] = value
            # å°† type å­—æ®µè½¬æ¢ä¸º class_typeï¼ˆComfyUI API éœ€è¦ï¼‰
            if "type" in converted_node:
                converted_node["class_type"] = converted_node["type"]
                # ä¿ç•™ type å­—æ®µï¼ˆæŸäº›æƒ…å†µä¸‹å¯èƒ½éœ€è¦ï¼‰
            prompt[node_id] = converted_node
        logger.info("å·²è½¬æ¢ nodes æ•°ç»„æ ¼å¼ä¸ºèŠ‚ç‚¹ ID key æ ¼å¼")
    else:
        # new_Wan22_api.json ä½¿ç”¨èŠ‚ç‚¹ ID key æ ¼å¼
        prompt = workflow_data
    
    # æ›´æ–°æ¨¡å‹åç§°ï¼ˆä»…å¯¹æ ‡å‡† workflowï¼‰
    if not is_mega_model and available_models:
        # æ›´æ–°èŠ‚ç‚¹ 122 å’Œ 549 çš„æ¨¡å‹åç§°ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        update_model_in_prompt(prompt, "122", available_models)
        update_model_in_prompt(prompt, "549", available_models)
    elif is_mega_model and available_models:
        # å¯¹äº Rapid-AIO-Mega.jsonï¼Œæ›´æ–°èŠ‚ç‚¹ 26 (CheckpointLoaderSimple) çš„æ¨¡å‹
        if "26" in prompt and "widgets_values" in prompt["26"]:
            current_model = prompt["26"]["widgets_values"][0] if prompt["26"]["widgets_values"] else ""
            # æŸ¥æ‰¾ MEGA/AIO æ¨¡å‹
            mega_models = [m for m in available_models if "mega" in m.lower() or "aio" in m.lower() or "all-in-one" in m.lower() or "allinone" in m.lower()]
            if mega_models:
                new_model = mega_models[0]
                if current_model != new_model:
                    prompt["26"]["widgets_values"][0] = new_model
                    logger.info(f"èŠ‚ç‚¹ 26 æ¨¡å‹æ›´æ–°: {current_model} -> {new_model}")
            elif available_models:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ° MEGA æ¨¡å‹ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹
                new_model = available_models[0]
                if current_model != new_model:
                    prompt["26"]["widgets_values"][0] = new_model
                    logger.info(f"èŠ‚ç‚¹ 26 æ¨¡å‹æ›´æ–°: {current_model} -> {new_model}")
    
    length = job_input.get("length", 81)
    # All-in-one æ¨¡å‹æ¨èä½¿ç”¨ 4 stepsï¼Œä½†ä¿æŒå‘åå…¼å®¹å…è®¸è‡ªå®šä¹‰
    steps = job_input.get("steps", 4)
    seed = job_input.get("seed", 42)
    cfg = job_input.get("cfg", 1.0)
    positive_prompt = job_input.get("prompt", "running man, grab the gun")
    negative_prompt = job_input.get("negative_prompt", "")
    
    # í•´ìƒë„(í­/ë†’ì´) 16ë°°ìˆ˜ ë³´ì •
    original_width = job_input.get("width", 480)
    original_height = job_input.get("height", 832)
    adjusted_width = to_nearest_multiple_of_16(original_width)
    adjusted_height = to_nearest_multiple_of_16(original_height)
    if adjusted_width != original_width:
        logger.info(f"Width adjusted to nearest multiple of 16: {original_width} -> {adjusted_width}")
    if adjusted_height != original_height:
        logger.info(f"Height adjusted to nearest multiple of 16: {original_height} -> {adjusted_height}")
    
    if is_mega_model:
        # Rapid-AIO-Mega.json workflow èŠ‚ç‚¹é…ç½®
        # èŠ‚ç‚¹16: LoadImage (èµ·å§‹å›¾åƒ)
        if "16" in prompt and "widgets_values" in prompt["16"]:
            prompt["16"]["widgets_values"][0] = image_path
            logger.info(f"èŠ‚ç‚¹16 (èµ·å§‹å›¾åƒ): {image_path}")
        
        # èŠ‚ç‚¹37: LoadImage (ç»“æŸå›¾åƒï¼Œå¯é€‰)
        if end_image_path_local and "37" in prompt and "widgets_values" in prompt["37"]:
            prompt["37"]["widgets_values"][0] = end_image_path_local
            logger.info(f"èŠ‚ç‚¹37 (ç»“æŸå›¾åƒ): {end_image_path_local}")
        
        # èŠ‚ç‚¹34: WanVideoVACEStartToEndFrame - widgets_values[0] æ˜¯ num_frames
        if "34" in prompt and "widgets_values" in prompt["34"]:
            prompt["34"]["widgets_values"][0] = length
            logger.info(f"èŠ‚ç‚¹34 (VACE num_frames): {length}")
        
        # èŠ‚ç‚¹48: PrimitiveInt - widgets_values[0] æ˜¯å¸§æ•°
        if "48" in prompt and "widgets_values" in prompt["48"]:
            prompt["48"]["widgets_values"][0] = length
            logger.info(f"èŠ‚ç‚¹48 (å¸§æ•°): {length}")
        
        # èŠ‚ç‚¹28: WanVaceToVideo - widgets_values[3] æ˜¯ strength (1=I2V), widgets_values[0] å’Œ widgets_values[1] æ˜¯å®½é«˜
        if "28" in prompt and "widgets_values" in prompt["28"]:
            prompt["28"]["widgets_values"][0] = adjusted_width
            prompt["28"]["widgets_values"][1] = adjusted_height
            prompt["28"]["widgets_values"][2] = length  # length
            prompt["28"]["widgets_values"][3] = 1  # strength = 1 for I2V
            prompt["28"]["widgets_values"][4] = 1  # ä¿æŒåŸå€¼
            logger.info(f"èŠ‚ç‚¹28 (WanVaceToVideo): width={adjusted_width}, height={adjusted_height}, length={length}, strength=1 (I2V)")
        
        # èŠ‚ç‚¹9: CLIPTextEncode (æ­£é¢æç¤ºè¯)
        if "9" in prompt and "widgets_values" in prompt["9"]:
            prompt["9"]["widgets_values"][0] = positive_prompt
            logger.info(f"èŠ‚ç‚¹9 (æ­£é¢æç¤ºè¯): {positive_prompt}")
        
        # èŠ‚ç‚¹10: CLIPTextEncode (è´Ÿé¢æç¤ºè¯)
        if "10" in prompt and "widgets_values" in prompt["10"]:
            prompt["10"]["widgets_values"][0] = negative_prompt
            logger.info(f"èŠ‚ç‚¹10 (è´Ÿé¢æç¤ºè¯): {negative_prompt}")
        
        # èŠ‚ç‚¹8: KSampler - widgets_values[0] æ˜¯ seed, widgets_values[2] æ˜¯ steps, widgets_values[3] æ˜¯ cfg
        if "8" in prompt and "widgets_values" in prompt["8"]:
            prompt["8"]["widgets_values"][0] = seed
            prompt["8"]["widgets_values"][2] = steps
            prompt["8"]["widgets_values"][3] = cfg
            logger.info(f"èŠ‚ç‚¹8 (KSampler): seed={seed}, steps={steps}, cfg={cfg}")
    else:
        # æ ‡å‡† workflow (new_Wan22_api.json) èŠ‚ç‚¹é…ç½®
        prompt["244"]["inputs"]["image"] = image_path
        prompt["541"]["inputs"]["num_frames"] = length
        # å½“æœ‰è¾“å…¥å›¾åƒæ—¶ï¼Œå¿…é¡»è®¾ç½® fun_or_fl2v_model ä¸º true ä»¥æ”¯æŒ I2V æ¨¡å¼
        if image_path and "541" in prompt and "inputs" in prompt["541"]:
            # å¼ºåˆ¶è®¾ç½®ä¸ºå¸ƒå°”å€¼ Trueï¼Œç¡®ä¿JSONåºåˆ—åŒ–æ­£ç¡®
            prompt["541"]["inputs"]["fun_or_fl2v_model"] = True
            # éªŒè¯è®¾ç½®æ˜¯å¦æˆåŠŸ
            actual_value = prompt["541"]["inputs"].get("fun_or_fl2v_model")
            logger.info(f"å·²è®¾ç½® fun_or_fl2v_model = {actual_value} (ç±»å‹: {type(actual_value).__name__}) ä»¥æ”¯æŒ I2V æ¨¡å¼")
        prompt["135"]["inputs"]["positive_prompt"] = positive_prompt
        prompt["220"]["inputs"]["seed"] = seed
        prompt["540"]["inputs"]["seed"] = seed
        prompt["540"]["inputs"]["cfg"] = cfg
        prompt["235"]["inputs"]["value"] = adjusted_width
        prompt["236"]["inputs"]["value"] = adjusted_height
    
    if not is_mega_model:
        # æ ‡å‡† workflow çš„ context_overlap å’Œ steps è®¾ç½®
        # context_overlap åŠ¨æ€è°ƒæ•´ï¼šç¡®ä¿ä¸è¶…è¿‡æ€»å¸§æ•°ï¼Œä¸”å¯¹çŸ­è§†é¢‘ä½¿ç”¨æ›´ä¿å®ˆçš„å€¼
        user_overlap = job_input.get("context_overlap")
        if user_overlap is not None:
            # ç”¨æˆ·æŒ‡å®šäº†å€¼ï¼Œä½†éœ€è¦ç¡®ä¿ä¸è¶…è¿‡æ€»å¸§æ•°
            context_overlap = min(user_overlap, length - 1) if length > 1 else 0
            if user_overlap != context_overlap:
                logger.warning(f"context_overlap {user_overlap} exceeds length {length}, adjusted to {context_overlap}")
        else:
            # è‡ªåŠ¨è®¡ç®—ï¼šå¯¹äºçŸ­è§†é¢‘ä½¿ç”¨æ›´å°çš„å€¼
            if length < 50:
                # çŸ­è§†é¢‘ï¼šæœ€å¤š 30% æˆ– 12ï¼Œå–è¾ƒå°å€¼
                context_overlap = min(12, max(1, int(length * 0.3)))
            else:
                # é•¿è§†é¢‘ï¼šæœ€å¤š 60% æˆ– 48ï¼Œå–è¾ƒå°å€¼
                context_overlap = min(48, max(12, int(length * 0.6)))
            logger.info(f"Auto-calculated context_overlap: {context_overlap} for length: {length}")
        
        if "498" in prompt:
            prompt["498"]["inputs"]["context_overlap"] = context_overlap
        
        # step ì„¤ì • ì ìš©
        if "834" in prompt:
            prompt["834"]["inputs"]["steps"] = steps
            logger.info(f"Steps set to: {steps}")
            lowsteps = int(steps*0.6)
            if "829" in prompt:
                prompt["829"]["inputs"]["step"] = lowsteps
                logger.info(f"LowSteps set to: {lowsteps}")

        # ì—”ë“œ ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš° 617ë²ˆ ë…¸ë“œì— ê²½ë¡œ ì ìš© (FLF2V ì „ìš©)
        if end_image_path_local and "617" in prompt:
            prompt["617"]["inputs"]["image"] = end_image_path_local
    
    # LoRA ì„¤ì • ì ìš©
    if lora_count > 0:
        if is_mega_model:
            # Rapid-AIO-Mega.json å¯èƒ½ä¸æ”¯æŒ LoRAï¼Œè®°å½•è­¦å‘Š
            logger.warning(f"Rapid-AIO-Mega workflow ä¸æ”¯æŒ LoRA è®¾ç½®ï¼Œå·²å¿½ç•¥ {lora_count} ä¸ª LoRA pairs")
        else:
            # æ ‡å‡† workflow çš„ LoRA è®¾ç½® - HIGH LoRAëŠ” ë…¸ë“œ 279, LOW LoRAëŠ” ë…¸ë“œ 553
            high_lora_node_id = "279"
            low_lora_node_id = "553"
            
            # ì…ë ¥ë°›ì€ LoRA pairs ì ìš© (lora_1ë¶€í„° ì‹œì‘)
            for i, lora_pair in enumerate(lora_pairs):
                if i < 4:  # ìµœëŒ€ 4ê°œê¹Œì§€ë§Œ
                    lora_high = lora_pair.get("high")
                    lora_low = lora_pair.get("low")
                    lora_high_weight = lora_pair.get("high_weight", 1.0)
                    lora_low_weight = lora_pair.get("low_weight", 1.0)
                    
                    # HIGH LoRA ì„¤ì • (ë…¸ë“œ 279ë²ˆ, lora_0ë¶€í„° ì‹œì‘)
                    if lora_high and high_lora_node_id in prompt:
                        prompt[high_lora_node_id]["inputs"][f"lora_{i}"] = lora_high
                        prompt[high_lora_node_id]["inputs"][f"strength_{i}"] = lora_high_weight
                        logger.info(f"LoRA {i+1} HIGH applied to node 279: {lora_high} with weight {lora_high_weight}")
                    
                    # LOW LoRA ì„¤ì • (ë…¸ë“œ 553ë²ˆ, lora_0ë¶€í„° ì‹œì‘)
                    if lora_low and low_lora_node_id in prompt:
                        prompt[low_lora_node_id]["inputs"][f"lora_{i}"] = lora_low
                        prompt[low_lora_node_id]["inputs"][f"strength_{i}"] = lora_low_weight
                        logger.info(f"LoRA {i+1} LOW applied to node 553: {lora_low} with weight {lora_low_weight}")

    # éªŒè¯å…³é”®å‚æ•°è®¾ç½® - æ— æ¡ä»¶è¾“å‡ºéªŒè¯ä¿¡æ¯
    logger.info("=" * 60)
    logger.info("éªŒè¯å…³é”®èŠ‚ç‚¹é…ç½®:")
    
    if is_mega_model:
        # Rapid-AIO-Mega.json éªŒè¯
        if "16" in prompt and "widgets_values" in prompt["16"]:
            image_in_16 = prompt["16"]["widgets_values"][0] if prompt["16"]["widgets_values"] else None
            logger.info(f"âœ“ èŠ‚ç‚¹16 (èµ·å§‹å›¾åƒ): {image_in_16}")
        if "28" in prompt and "widgets_values" in prompt["28"]:
            widgets = prompt["28"]["widgets_values"]
            logger.info(f"âœ“ èŠ‚ç‚¹28 (WanVaceToVideo): width={widgets[0]}, height={widgets[1]}, length={widgets[2]}, strength={widgets[3]} (I2V)")
        if "34" in prompt and "widgets_values" in prompt["34"]:
            num_frames_34 = prompt["34"]["widgets_values"][0] if prompt["34"]["widgets_values"] else None
            logger.info(f"âœ“ èŠ‚ç‚¹34 (VACE num_frames): {num_frames_34}")
        if "8" in prompt and "widgets_values" in prompt["8"]:
            widgets = prompt["8"]["widgets_values"]
            logger.info(f"âœ“ èŠ‚ç‚¹8 (KSampler): seed={widgets[0]}, steps={widgets[2]}, cfg={widgets[3]}")
    else:
        # æ ‡å‡† workflow éªŒè¯
        if "244" in prompt:
            if "inputs" in prompt["244"]:
                image_in_244 = prompt["244"]["inputs"].get("image")
                logger.info(f"âœ“ èŠ‚ç‚¹244 (LoadImage): image = {image_in_244}")
            else:
                logger.warning("âœ— èŠ‚ç‚¹244 ç¼ºå°‘ inputs")
        else:
            logger.warning("âœ— èŠ‚ç‚¹244 ä¸å­˜åœ¨")
        
        if "541" in prompt:
            if "inputs" in prompt["541"]:
                fun_or_fl2v_value = prompt["541"]["inputs"].get("fun_or_fl2v_model")
                logger.info(f"âœ“ èŠ‚ç‚¹541 (WanVideoImageToVideoEncode): fun_or_fl2v_model = {fun_or_fl2v_value} (ç±»å‹: {type(fun_or_fl2v_value).__name__})")
                if fun_or_fl2v_value != True:
                    logger.warning(f"âš  è­¦å‘Š: fun_or_fl2v_model ä¸æ˜¯ Trueï¼Œå®é™…å€¼: {fun_or_fl2v_value}")
                
                num_frames = prompt["541"]["inputs"].get("num_frames")
                logger.info(f"  - num_frames = {num_frames}")
            else:
                logger.warning("âœ— èŠ‚ç‚¹541 ç¼ºå°‘ inputs")
        else:
            logger.warning("âœ— èŠ‚ç‚¹541 ä¸å­˜åœ¨")
    
    logger.info("=" * 60)
    
    ws_url = f"ws://{server_address}:8188/ws?clientId={client_id}"
    logger.info(f"Connecting to WebSocket: {ws_url}")
    
    # ë¨¼ì € HTTP ì—°ê²°ì´ ê°€ëŠ¥í•œì§€ í™•ì¸
    http_url = f"http://{server_address}:8188/"
    logger.info(f"Checking HTTP connection to: {http_url}")
    
    # HTTP ì—°ê²° í™•ì¸ (ìµœëŒ€ 1ë¶„)
    max_http_attempts = 180
    for http_attempt in range(max_http_attempts):
        try:
            import urllib.request
            response = urllib.request.urlopen(http_url, timeout=5)
            logger.info(f"HTTP ì—°ê²° ì„±ê³µ (ì‹œë„ {http_attempt+1})")
            break
        except Exception as e:
            logger.warning(f"HTTP ì—°ê²° ì‹¤íŒ¨ (ì‹œë„ {http_attempt+1}/{max_http_attempts}): {e}")
            if http_attempt == max_http_attempts - 1:
                raise Exception("ComfyUI ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
            time.sleep(1)
    
    ws = websocket.WebSocket()
    # ì›¹ì†Œì¼“ ì—°ê²° ì‹œë„ (ìµœëŒ€ 3ë¶„)
    max_attempts = int(180/5)  # 3ë¶„ (1ì´ˆì— í•œ ë²ˆì”© ì‹œë„)
    for attempt in range(max_attempts):
        import time
        try:
            ws.connect(ws_url)
            logger.info(f"ì›¹ì†Œì¼“ ì—°ê²° ì„±ê³µ (ì‹œë„ {attempt+1})")
            break
        except Exception as e:
            logger.warning(f"ì›¹ì†Œì¼“ ì—°ê²° ì‹¤íŒ¨ (ì‹œë„ {attempt+1}/{max_attempts}): {e}")
            if attempt == max_attempts - 1:
                raise Exception("ì›¹ì†Œì¼“ ì—°ê²° ì‹œê°„ ì´ˆê³¼ (3ë¶„)")
            time.sleep(5)
    try:
        videos = get_videos(ws, prompt, is_mega_model)
        ws.close()

        # ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
        for node_id in videos:
            if videos[node_id]:
                return {"video": videos[node_id][0]}
        
        return {"error": "ë¹„ë””ì˜¤ë¥¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
    except Exception as e:
        ws.close()
        error_message = str(e)
        logger.error(f"Video generation failed: {error_message}")
        return {"error": error_message}

if __name__ == "__main__":
    runpod.serverless.start({"handler": handler})