import runpod
from runpod.serverless.utils import rp_upload
import os
import websocket
import base64
import json
import uuid
import logging
import urllib.request
import urllib.parse
import binascii # Base64 ì—ëŸ¬ ì²˜ë¦¬ë¥¼ ìœ„í•´ import
import subprocess
import time
# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


server_address = os.getenv('SERVER_ADDRESS', '127.0.0.1')
client_id = str(uuid.uuid4())
def to_nearest_multiple_of_16(value):
    """ì£¼ì–´ì§„ ê°’ì„ ê°€ì¥ ê°€ê¹Œìš´ 16ì˜ ë°°ìˆ˜ë¡œ ë³´ì •, ìµœì†Œ 16 ë³´ì¥"""
    try:
        numeric_value = float(value)
    except Exception:
        raise Exception(f"width/height ê°’ì´ ìˆ«ìê°€ ì•„ë‹™ë‹ˆë‹¤: {value}")
    adjusted = int(round(numeric_value / 16.0) * 16)
    if adjusted < 16:
        adjusted = 16
    return adjusted
def process_input(input_data, temp_dir, output_filename, input_type):
    """ì…ë ¥ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ì—¬ íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    if input_type == "path":
        # ê²½ë¡œì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
        logger.info(f"ğŸ“ ê²½ë¡œ ì…ë ¥ ì²˜ë¦¬: {input_data}")
        return input_data
    elif input_type == "url":
        # URLì¸ ê²½ìš° ë‹¤ìš´ë¡œë“œ
        logger.info(f"ğŸŒ URL ì…ë ¥ ì²˜ë¦¬: {input_data}")
        os.makedirs(temp_dir, exist_ok=True)
        file_path = os.path.abspath(os.path.join(temp_dir, output_filename))
        return download_file_from_url(input_data, file_path)
    elif input_type == "base64":
        # Base64ì¸ ê²½ìš° ë””ì½”ë”©í•˜ì—¬ ì €ì¥
        logger.info(f"ğŸ”¢ Base64 ì…ë ¥ ì²˜ë¦¬")
        return save_base64_to_file(input_data, temp_dir, output_filename)
    else:
        raise Exception(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì…ë ¥ íƒ€ì…: {input_type}")

        
def download_file_from_url(url, output_path):
    """URLì—ì„œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    try:
        # wgetì„ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        result = subprocess.run([
            'wget', '-O', output_path, '--no-verbose', url
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            logger.info(f"âœ… URLì—ì„œ íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí–ˆìŠµë‹ˆë‹¤: {url} -> {output_path}")
            return output_path
        else:
            logger.error(f"âŒ wget ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {result.stderr}")
            raise Exception(f"URL ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {result.stderr}")
    except subprocess.TimeoutExpired:
        logger.error("âŒ ë‹¤ìš´ë¡œë“œ ì‹œê°„ ì´ˆê³¼")
        raise Exception("ë‹¤ìš´ë¡œë“œ ì‹œê°„ ì´ˆê³¼")
    except Exception as e:
        logger.error(f"âŒ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise Exception(f"ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


def save_base64_to_file(base64_data, temp_dir, output_filename):
    """Base64 ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # Base64 ë¬¸ìì—´ ë””ì½”ë”©
        decoded_data = base64.b64decode(base64_data)
        
        # ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
        os.makedirs(temp_dir, exist_ok=True)
        
        # íŒŒì¼ë¡œ ì €ì¥
        file_path = os.path.abspath(os.path.join(temp_dir, output_filename))
        with open(file_path, 'wb') as f:
            f.write(decoded_data)
        
        logger.info(f"âœ… Base64 ì…ë ¥ì„ '{file_path}' íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        return file_path
    except (binascii.Error, ValueError) as e:
        logger.error(f"âŒ Base64 ë””ì½”ë”© ì‹¤íŒ¨: {e}")
        raise Exception(f"Base64 ë””ì½”ë”© ì‹¤íŒ¨: {e}")
    
def queue_prompt(prompt):
    url = f"http://{server_address}:8188/prompt"
    logger.info(f"Queueing prompt to: {url}")
    p = {"prompt": prompt, "client_id": client_id}
    data = json.dumps(p).encode('utf-8')
    req = urllib.request.Request(url, data=data)
    req.add_header('Content-Type', 'application/json')
    try:
        response = urllib.request.urlopen(req)
        return json.loads(response.read())
    except urllib.error.HTTPError as e:
        error_body = e.read().decode('utf-8')
        logger.error(f"HTTP Error {e.code}: {e.reason}")
        logger.error(f"Error response: {error_body}")
        try:
            error_json = json.loads(error_body)
            logger.error(f"Error details: {json.dumps(error_json, indent=2)}")
        except:
            pass
        raise Exception(f"ComfyUI API é”™è¯¯ ({e.code}): {error_body}")

def get_image(filename, subfolder, folder_type):
    url = f"http://{server_address}:8188/view"
    logger.info(f"Getting image from: {url}")
    data = {"filename": filename, "subfolder": subfolder, "type": folder_type}
    url_values = urllib.parse.urlencode(data)
    with urllib.request.urlopen(f"{url}?{url_values}") as response:
        return response.read()

def get_history(prompt_id):
    url = f"http://{server_address}:8188/history/{prompt_id}"
    logger.info(f"Getting history from: {url}")
    with urllib.request.urlopen(url) as response:
        return json.loads(response.read())

def get_videos(ws, prompt):
    prompt_id = queue_prompt(prompt)['prompt_id']
    output_videos = {}
    error_info = None
    
    while True:
        out = ws.recv()
        if isinstance(out, str):
            message = json.loads(out)
            if message['type'] == 'executing':
                data = message['data']
                if data['node'] is None and data['prompt_id'] == prompt_id:
                    break
            elif message['type'] == 'execution_error':
                # æ•è·æ‰§è¡Œé”™è¯¯
                error_info = message.get('data', {}).get('error', 'Unknown execution error')
                logger.error(f"Execution error received: {error_info}")
        else:
            continue

    history = get_history(prompt_id)[prompt_id]
    
    # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯ä¿¡æ¯
    if 'error' in history:
        error_info = history['error']
        if isinstance(error_info, dict):
            error_info = error_info.get('message', str(error_info))
        logger.error(f"Error in history: {error_info}")
        raise Exception(f"ComfyUI execution error: {error_info}")
    
    # æ£€æŸ¥ outputs æ˜¯å¦å­˜åœ¨
    if 'outputs' not in history:
        if error_info:
            raise Exception(f"ComfyUI execution error: {error_info}")
        raise Exception("No outputs found in execution history")
    
    for node_id in history['outputs']:
        node_output = history['outputs'][node_id]
        videos_output = []
        if 'gifs' in node_output:
            for video in node_output['gifs']:
                # fullpathë¥¼ ì´ìš©í•˜ì—¬ ì§ì ‘ íŒŒì¼ì„ ì½ê³  base64ë¡œ ì¸ì½”ë”©
                with open(video['fullpath'], 'rb') as f:
                    video_data = base64.b64encode(f.read()).decode('utf-8')
                videos_output.append(video_data)
        output_videos[node_id] = videos_output

    return output_videos

def get_available_models():
    """è·å– ComfyUI ä¸­å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
    try:
        url = f"http://{server_address}:8188/object_info"
        with urllib.request.urlopen(url, timeout=5) as response:
            object_info = json.loads(response.read())
            # WanVideoModelLoader çš„å¯ç”¨æ¨¡å‹
            if "WanVideoModelLoader" in object_info:
                loader_info = object_info["WanVideoModelLoader"]
                # å°è¯•ä¸åŒçš„è¿”å›æ ¼å¼
                if "model" in loader_info:
                    models = loader_info["model"]
                elif "input" in loader_info and "required" in loader_info["input"]:
                    if "model" in loader_info["input"]["required"]:
                        models = loader_info["input"]["required"]["model"]
                    else:
                        models = []
                else:
                    models = []
                
                # å¤„ç†åµŒå¥—åˆ—è¡¨çš„æƒ…å†µï¼šå¦‚æœ models æ˜¯åˆ—è¡¨ä¸”ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œåˆ™æå–ç¬¬ä¸€ä¸ªå…ƒç´ 
                if models and isinstance(models, list) and len(models) > 0:
                    if isinstance(models[0], list):
                        # ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯åˆ—è¡¨ï¼Œæå–å®ƒ
                        models = models[0]
                    # è¿‡æ»¤æ‰éå­—ç¬¦ä¸²å…ƒç´ ï¼ˆå¦‚å­—å…¸ï¼‰
                    models = [m for m in models if isinstance(m, str)]
                
                if models:
                    logger.info(f"å¯ç”¨æ¨¡å‹åˆ—è¡¨: {models}")
                return models if models else []
            return []
    except Exception as e:
        logger.warning(f"è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
        return []

def update_model_in_prompt(prompt, node_id, available_models):
    """æ›´æ–° prompt ä¸­æŒ‡å®šèŠ‚ç‚¹çš„æ¨¡å‹åç§°ï¼Œå¦‚æœæ¨¡å‹ä¸å­˜åœ¨åˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹"""
    if node_id not in prompt:
        return False
    
    node = prompt[node_id]
    if "inputs" not in node or "model" not in node["inputs"]:
        return False
    
    current_model = node["inputs"]["model"]
    logger.info(f"èŠ‚ç‚¹ {node_id} é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹: {current_model}")
    
    # å¦‚æœå½“å‰æ¨¡å‹åœ¨å¯ç”¨åˆ—è¡¨ä¸­ï¼Œä¸éœ€è¦æ›´æ–°
    if current_model in available_models:
        logger.info(f"èŠ‚ç‚¹ {node_id} ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹: {current_model}")
        return False
    
    # ä¼˜å…ˆé€‰æ‹© I2V ç›¸å…³çš„æ¨¡å‹ï¼ˆåŒ…å« I2V å…³é”®å­—ï¼‰
    i2v_models = [m for m in available_models if "I2V" in m.upper() or "i2v" in m.lower()]
    if i2v_models:
        new_model = i2v_models[0]
        logger.info(f"èŠ‚ç‚¹ {node_id} æ¨¡å‹æ›´æ–°: {current_model} -> {new_model} (é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹ä¸åœ¨å¯ç”¨åˆ—è¡¨ä¸­ï¼Œå·²è‡ªåŠ¨æ›¿æ¢ä¸º I2V æ¨¡å‹)")
        node["inputs"]["model"] = new_model
        return True
    
    # å¦‚æœæ²¡æœ‰ I2V æ¨¡å‹ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹
    if available_models:
        new_model = available_models[0]
        logger.info(f"èŠ‚ç‚¹ {node_id} æ¨¡å‹æ›´æ–°: {current_model} -> {new_model} (é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹ä¸åœ¨å¯ç”¨åˆ—è¡¨ä¸­ï¼Œå·²è‡ªåŠ¨æ›¿æ¢ä¸ºç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹)")
        node["inputs"]["model"] = new_model
        return True
    
    return False

def load_workflow(workflow_path):
    """åŠ è½½å¹¶éªŒè¯å·¥ä½œæµJSONæ–‡ä»¶"""
    if not os.path.exists(workflow_path):
        raise FileNotFoundError(f"å·¥ä½œæµæ–‡ä»¶ä¸å­˜åœ¨: {workflow_path}")
    
    file_size = os.path.getsize(workflow_path)
    logger.info(f"åŠ è½½å·¥ä½œæµæ–‡ä»¶: {workflow_path} (å¤§å°: {file_size} å­—èŠ‚)")
    
    if file_size == 0:
        raise ValueError(f"å·¥ä½œæµæ–‡ä»¶ä¸ºç©º: {workflow_path}")
    
    try:
        with open(workflow_path, 'r', encoding='utf-8') as file:
            content = file.read()
            # æ£€æŸ¥æ–‡ä»¶å†…å®¹æ˜¯å¦çœ‹èµ·æ¥åƒJSONï¼ˆä»¥{æˆ–[å¼€å¤´ï¼‰
            content_stripped = content.strip()
            if not content_stripped.startswith(('{', '[')):
                # æ˜¾ç¤ºå‰500ä¸ªå­—ç¬¦ä»¥ä¾¿è°ƒè¯•
                preview = content[:500] if len(content) > 500 else content
                logger.error(f"æ–‡ä»¶å†…å®¹ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚å‰500å­—ç¬¦: {preview}")
                raise ValueError(f"å·¥ä½œæµæ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼: {workflow_path}")
            
            return json.loads(content)
    except json.JSONDecodeError as e:
        # æ˜¾ç¤ºé”™è¯¯ä½ç½®é™„è¿‘çš„å†…å®¹
        with open(workflow_path, 'r', encoding='utf-8') as file:
            lines = file.readlines()
            error_line = e.lineno - 1 if e.lineno > 0 else 0
            start_line = max(0, error_line - 2)
            end_line = min(len(lines), error_line + 3)
            context = ''.join(lines[start_line:end_line])
            logger.error(f"JSONè§£æé”™è¯¯ (è¡Œ {e.lineno}, åˆ— {e.colno}):\n{context}")
        raise ValueError(f"å·¥ä½œæµæ–‡ä»¶JSONæ ¼å¼é”™è¯¯: {workflow_path} - {str(e)}")
    except Exception as e:
        logger.error(f"åŠ è½½å·¥ä½œæµæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {workflow_path} - {str(e)}")
        raise

def handler(job):
    job_input = job.get("input", {})

    # è®°å½•job_inputï¼Œä½†æ’é™¤base64æ•°æ®ä»¥é¿å…æ—¥å¿—è¿‡é•¿
    log_input = {k: v for k, v in job_input.items() if k not in ["image_base64", "end_image_base64"]}
    if "image_base64" in job_input:
        log_input["image_base64"] = f"<base64 data, length: {len(job_input['image_base64'])}>"
    if "end_image_base64" in job_input:
        log_input["end_image_base64"] = f"<base64 data, length: {len(job_input['end_image_base64'])}>"
    logger.info(f"Received job input: {log_input}")
    task_id = f"task_{uuid.uuid4()}"

    # ì´ë¯¸ì§€ ì…ë ¥ ì²˜ë¦¬ (image_path, image_url, image_base64 ì¤‘ í•˜ë‚˜ë§Œ ì‚¬ìš©)
    image_path = None
    if "image_path" in job_input:
        image_path = process_input(job_input["image_path"], task_id, "input_image.jpg", "path")
    elif "image_url" in job_input:
        image_path = process_input(job_input["image_url"], task_id, "input_image.jpg", "url")
    elif "image_base64" in job_input:
        image_path = process_input(job_input["image_base64"], task_id, "input_image.jpg", "base64")
    else:
        # ê¸°ë³¸ê°’ ì‚¬ìš©
        image_path = "/example_image.png"
        logger.info("ê¸°ë³¸ ì´ë¯¸ì§€ íŒŒì¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤: /example_image.png")

    # ì—”ë“œ ì´ë¯¸ì§€ ì…ë ¥ ì²˜ë¦¬ (end_image_path, end_image_url, end_image_base64 ì¤‘ í•˜ë‚˜ë§Œ ì‚¬ìš©)
    end_image_path_local = None
    if "end_image_path" in job_input:
        end_image_path_local = process_input(job_input["end_image_path"], task_id, "end_image.jpg", "path")
    elif "end_image_url" in job_input:
        end_image_path_local = process_input(job_input["end_image_url"], task_id, "end_image.jpg", "url")
    elif "end_image_base64" in job_input:
        end_image_path_local = process_input(job_input["end_image_base64"], task_id, "end_image.jpg", "base64")
    
    # LoRA ì„¤ì • í™•ì¸ - ë°°ì—´ë¡œ ë°›ì•„ì„œ ì²˜ë¦¬
    lora_pairs = job_input.get("lora_pairs", [])
    
    # ìµœëŒ€ 4ê°œ LoRAê¹Œì§€ ì§€ì›
    lora_count = min(len(lora_pairs), 4)
    if lora_count > len(lora_pairs):
        logger.warning(f"LoRA ê°œìˆ˜ê°€ {len(lora_pairs)}ê°œì…ë‹ˆë‹¤. ìµœëŒ€ 4ê°œê¹Œì§€ë§Œ ì§€ì›ë©ë‹ˆë‹¤. ì²˜ìŒ 4ê°œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        lora_pairs = lora_pairs[:4]
    
    # ì›Œí¬í”Œë¡œìš° íŒŒì¼ ì„ íƒ (end_image_*ê°€ ìˆìœ¼ë©´ FLF2V ì›Œí¬í”Œë¡œ ì‚¬ìš©)
    workflow_file = "/new_Wan22_flf2v_api.json" if end_image_path_local else "/new_Wan22_api.json"
    logger.info(f"Using {'FLF2V' if end_image_path_local else 'single'} workflow with {lora_count} LoRA pairs")
    
    prompt = load_workflow(workflow_file)
    
    # è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨å¹¶è‡ªåŠ¨æ›´æ–° workflow ä¸­çš„æ¨¡å‹åç§°
    available_models = get_available_models()
    if available_models:
        # æ›´æ–°èŠ‚ç‚¹ 122 å’Œ 549 çš„æ¨¡å‹åç§°ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        update_model_in_prompt(prompt, "122", available_models)
        update_model_in_prompt(prompt, "549", available_models)
    
    # æ£€æµ‹æ˜¯å¦ä¸º MEGA/AIO æ¨¡å‹ï¼ˆæ”¯æŒ I2V å’Œ T2V çš„ all-in-one æ¨¡å‹ï¼‰
    is_mega_model = False
    model_names_checked = []
    
    # æ£€æŸ¥èŠ‚ç‚¹ 122 çš„æ¨¡å‹åç§°ï¼ˆHIGH æ¨¡å‹ï¼‰
    if "122" in prompt and "inputs" in prompt["122"] and "model" in prompt["122"]["inputs"]:
        model_name = prompt["122"]["inputs"]["model"]
        model_names_checked.append(model_name)
        model_name_lower = model_name.lower()
        if "mega" in model_name_lower or "aio" in model_name_lower or "all-in-one" in model_name_lower or "allinone" in model_name_lower:
            is_mega_model = True
            logger.info(f"æ£€æµ‹åˆ° MEGA/AIO æ¨¡å‹ (èŠ‚ç‚¹ 122): {model_name}, å¯ç”¨ fun_or_fl2v_model æ¨¡å¼")
    
    # æ£€æŸ¥èŠ‚ç‚¹ 549 çš„æ¨¡å‹åç§°ï¼ˆLOW æ¨¡å‹ï¼‰
    if "549" in prompt and "inputs" in prompt["549"] and "model" in prompt["549"]["inputs"]:
        model_name = prompt["549"]["inputs"]["model"]
        if model_name not in model_names_checked:
            model_names_checked.append(model_name)
            model_name_lower = model_name.lower()
            if "mega" in model_name_lower or "aio" in model_name_lower or "all-in-one" in model_name_lower or "allinone" in model_name_lower:
                is_mega_model = True
                logger.info(f"æ£€æµ‹åˆ° MEGA/AIO æ¨¡å‹ (èŠ‚ç‚¹ 549): {model_name}, å¯ç”¨ fun_or_fl2v_model æ¨¡å¼")
    
    length = job_input.get("length", 81)
    # All-in-one æ¨¡å‹æ¨èä½¿ç”¨ 4 stepsï¼Œä½†ä¿æŒå‘åå…¼å®¹å…è®¸è‡ªå®šä¹‰
    steps = job_input.get("steps", 4)

    prompt["244"]["inputs"]["image"] = image_path
    prompt["541"]["inputs"]["num_frames"] = length
    # å½“æœ‰è¾“å…¥å›¾åƒæ—¶ï¼Œå¿…é¡»è®¾ç½® fun_or_fl2v_model ä¸º true ä»¥æ”¯æŒ I2V æ¨¡å¼
    # è¿™å¯¹äº MEGA/AIO æ¨¡å‹æ˜¯å¿…éœ€çš„ï¼Œå¯¹äºå…¶ä»–æ¨¡å‹ä¹Ÿå¯èƒ½éœ€è¦
    if image_path and "541" in prompt and "inputs" in prompt["541"]:
        prompt["541"]["inputs"]["fun_or_fl2v_model"] = True
        if is_mega_model:
            logger.info("å·²è®¾ç½® fun_or_fl2v_model = True ä»¥æ”¯æŒ MEGA æ¨¡å‹çš„ I2V æ¨¡å¼")
        else:
            logger.info("å·²è®¾ç½® fun_or_fl2v_model = True ä»¥æ”¯æŒ I2V æ¨¡å¼ï¼ˆæ£€æµ‹åˆ°è¾“å…¥å›¾åƒï¼‰")
    prompt["135"]["inputs"]["positive_prompt"] = job_input.get("prompt", "running man, grab the gun")
    prompt["220"]["inputs"]["seed"] = job_input.get("seed", 42)
    prompt["540"]["inputs"]["seed"] = job_input.get("seed", 42)
    # All-in-one æ¨¡å‹æ¨è CFG=1.0
    prompt["540"]["inputs"]["cfg"] = job_input.get("cfg", 1.0)
    # í•´ìƒë„(í­/ë†’ì´) 16ë°°ìˆ˜ ë³´ì •
    original_width = job_input.get("width", 480)
    original_height = job_input.get("height", 832)
    adjusted_width = to_nearest_multiple_of_16(original_width)
    adjusted_height = to_nearest_multiple_of_16(original_height)
    if adjusted_width != original_width:
        logger.info(f"Width adjusted to nearest multiple of 16: {original_width} -> {adjusted_width}")
    if adjusted_height != original_height:
        logger.info(f"Height adjusted to nearest multiple of 16: {original_height} -> {adjusted_height}")
    prompt["235"]["inputs"]["value"] = adjusted_width
    prompt["236"]["inputs"]["value"] = adjusted_height
    
    # context_overlap åŠ¨æ€è°ƒæ•´ï¼šç¡®ä¿ä¸è¶…è¿‡æ€»å¸§æ•°ï¼Œä¸”å¯¹çŸ­è§†é¢‘ä½¿ç”¨æ›´ä¿å®ˆçš„å€¼
    user_overlap = job_input.get("context_overlap")
    if user_overlap is not None:
        # ç”¨æˆ·æŒ‡å®šäº†å€¼ï¼Œä½†éœ€è¦ç¡®ä¿ä¸è¶…è¿‡æ€»å¸§æ•°
        context_overlap = min(user_overlap, length - 1) if length > 1 else 0
        if user_overlap != context_overlap:
            logger.warning(f"context_overlap {user_overlap} exceeds length {length}, adjusted to {context_overlap}")
    else:
        # è‡ªåŠ¨è®¡ç®—ï¼šå¯¹äºçŸ­è§†é¢‘ä½¿ç”¨æ›´å°çš„å€¼
        if length < 50:
            # çŸ­è§†é¢‘ï¼šæœ€å¤š 30% æˆ– 12ï¼Œå–è¾ƒå°å€¼
            context_overlap = min(12, max(1, int(length * 0.3)))
        else:
            # é•¿è§†é¢‘ï¼šæœ€å¤š 60% æˆ– 48ï¼Œå–è¾ƒå°å€¼
            context_overlap = min(48, max(12, int(length * 0.6)))
        logger.info(f"Auto-calculated context_overlap: {context_overlap} for length: {length}")
    
    prompt["498"]["inputs"]["context_overlap"] = context_overlap
    
    # step ì„¤ì • ì ìš©
    if "834" in prompt:
        prompt["834"]["inputs"]["steps"] = steps
        logger.info(f"Steps set to: {steps}")
        lowsteps = int(steps*0.6)
        prompt["829"]["inputs"]["step"] = lowsteps
        logger.info(f"LowSteps set to: {lowsteps}")

    # ì—”ë“œ ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš° 617ë²ˆ ë…¸ë“œì— ê²½ë¡œ ì ìš© (FLF2V ì „ìš©)
    if end_image_path_local:
        prompt["617"]["inputs"]["image"] = end_image_path_local
    
    # LoRA ì„¤ì • ì ìš© - HIGH LoRAëŠ” ë…¸ë“œ 279, LOW LoRAëŠ” ë…¸ë“œ 553
    if lora_count > 0:
        # HIGH LoRA ë…¸ë“œ (279ë²ˆ)
        high_lora_node_id = "279"
        
        # LOW LoRA ë…¸ë“œ (553ë²ˆ)
        low_lora_node_id = "553"
        
        # ì…ë ¥ë°›ì€ LoRA pairs ì ìš© (lora_1ë¶€í„° ì‹œì‘)
        for i, lora_pair in enumerate(lora_pairs):
            if i < 4:  # ìµœëŒ€ 4ê°œê¹Œì§€ë§Œ
                lora_high = lora_pair.get("high")
                lora_low = lora_pair.get("low")
                lora_high_weight = lora_pair.get("high_weight", 1.0)
                lora_low_weight = lora_pair.get("low_weight", 1.0)
                
                # HIGH LoRA ì„¤ì • (ë…¸ë“œ 279ë²ˆ, lora_0ë¶€í„° ì‹œì‘)
                if lora_high:
                    prompt[high_lora_node_id]["inputs"][f"lora_{i}"] = lora_high
                    prompt[high_lora_node_id]["inputs"][f"strength_{i}"] = lora_high_weight
                    logger.info(f"LoRA {i+1} HIGH applied to node 279: {lora_high} with weight {lora_high_weight}")
                
                # LOW LoRA ì„¤ì • (ë…¸ë“œ 553ë²ˆ, lora_0ë¶€í„° ì‹œì‘)
                if lora_low:
                    prompt[low_lora_node_id]["inputs"][f"lora_{i}"] = lora_low
                    prompt[low_lora_node_id]["inputs"][f"strength_{i}"] = lora_low_weight
                    logger.info(f"LoRA {i+1} LOW applied to node 553: {lora_low} with weight {lora_low_weight}")

    ws_url = f"ws://{server_address}:8188/ws?clientId={client_id}"
    logger.info(f"Connecting to WebSocket: {ws_url}")
    
    # ë¨¼ì € HTTP ì—°ê²°ì´ ê°€ëŠ¥í•œì§€ í™•ì¸
    http_url = f"http://{server_address}:8188/"
    logger.info(f"Checking HTTP connection to: {http_url}")
    
    # HTTP ì—°ê²° í™•ì¸ (ìµœëŒ€ 1ë¶„)
    max_http_attempts = 180
    for http_attempt in range(max_http_attempts):
        try:
            import urllib.request
            response = urllib.request.urlopen(http_url, timeout=5)
            logger.info(f"HTTP ì—°ê²° ì„±ê³µ (ì‹œë„ {http_attempt+1})")
            break
        except Exception as e:
            logger.warning(f"HTTP ì—°ê²° ì‹¤íŒ¨ (ì‹œë„ {http_attempt+1}/{max_http_attempts}): {e}")
            if http_attempt == max_http_attempts - 1:
                raise Exception("ComfyUI ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
            time.sleep(1)
    
    ws = websocket.WebSocket()
    # ì›¹ì†Œì¼“ ì—°ê²° ì‹œë„ (ìµœëŒ€ 3ë¶„)
    max_attempts = int(180/5)  # 3ë¶„ (1ì´ˆì— í•œ ë²ˆì”© ì‹œë„)
    for attempt in range(max_attempts):
        import time
        try:
            ws.connect(ws_url)
            logger.info(f"ì›¹ì†Œì¼“ ì—°ê²° ì„±ê³µ (ì‹œë„ {attempt+1})")
            break
        except Exception as e:
            logger.warning(f"ì›¹ì†Œì¼“ ì—°ê²° ì‹¤íŒ¨ (ì‹œë„ {attempt+1}/{max_attempts}): {e}")
            if attempt == max_attempts - 1:
                raise Exception("ì›¹ì†Œì¼“ ì—°ê²° ì‹œê°„ ì´ˆê³¼ (3ë¶„)")
            time.sleep(5)
    try:
        videos = get_videos(ws, prompt)
        ws.close()

        # ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
        for node_id in videos:
            if videos[node_id]:
                return {"video": videos[node_id][0]}
        
        return {"error": "ë¹„ë””ì˜¤ë¥¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
    except Exception as e:
        ws.close()
        error_message = str(e)
        logger.error(f"Video generation failed: {error_message}")
        return {"error": error_message}

if __name__ == "__main__":
    runpod.serverless.start({"handler": handler})