import runpod
from runpod.serverless.utils import rp_upload
import os
import websocket
import base64
import json
import uuid
import logging
import urllib.request
import urllib.parse
import binascii # Base64 ì—ëŸ¬ ì²˜ë¦¬ë¥¼ ìœ„í•´ import
import subprocess
import time
# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


server_address = os.getenv('SERVER_ADDRESS', '127.0.0.1')
client_id = str(uuid.uuid4())
def to_nearest_multiple_of_16(value):
    """ì£¼ì–´ì§„ ê°’ì„ ê°€ì¥ ê°€ê¹Œìš´ 16ì˜ ë°°ìˆ˜ë¡œ ë³´ì •, ìµœì†Œ 16 ë³´ì¥"""
    try:
        numeric_value = float(value)
    except Exception:
        raise Exception(f"width/height ê°’ì´ ìˆ«ìê°€ ì•„ë‹™ë‹ˆë‹¤: {value}")
    adjusted = int(round(numeric_value / 16.0) * 16)
    if adjusted < 16:
        adjusted = 16
    return adjusted
def process_input(input_data, temp_dir, output_filename, input_type):
    """ì…ë ¥ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ì—¬ íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    if input_type == "path":
        # ê²½ë¡œì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
        logger.info(f"ğŸ“ ê²½ë¡œ ì…ë ¥ ì²˜ë¦¬: {input_data}")
        return input_data
    elif input_type == "url":
        # URLì¸ ê²½ìš° ë‹¤ìš´ë¡œë“œ
        logger.info(f"ğŸŒ URL ì…ë ¥ ì²˜ë¦¬: {input_data}")
        os.makedirs(temp_dir, exist_ok=True)
        file_path = os.path.abspath(os.path.join(temp_dir, output_filename))
        return download_file_from_url(input_data, file_path)
    elif input_type == "base64":
        # Base64ì¸ ê²½ìš° ë””ì½”ë”©í•˜ì—¬ ì €ì¥
        logger.info(f"ğŸ”¢ Base64 ì…ë ¥ ì²˜ë¦¬")
        return save_base64_to_file(input_data, temp_dir, output_filename)
    else:
        raise Exception(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì…ë ¥ íƒ€ì…: {input_type}")

        
def download_file_from_url(url, output_path):
    """URLì—ì„œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    try:
        # wgetì„ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        result = subprocess.run([
            'wget', '-O', output_path, '--no-verbose', url
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            logger.info(f"âœ… URLì—ì„œ íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí–ˆìŠµë‹ˆë‹¤: {url} -> {output_path}")
            return output_path
        else:
            logger.error(f"âŒ wget ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {result.stderr}")
            raise Exception(f"URL ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {result.stderr}")
    except subprocess.TimeoutExpired:
        logger.error("âŒ ë‹¤ìš´ë¡œë“œ ì‹œê°„ ì´ˆê³¼")
        raise Exception("ë‹¤ìš´ë¡œë“œ ì‹œê°„ ì´ˆê³¼")
    except Exception as e:
        logger.error(f"âŒ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise Exception(f"ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


def save_base64_to_file(base64_data, temp_dir, output_filename):
    """Base64 ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    try:
        # Base64 ë¬¸ìì—´ ë””ì½”ë”©
        decoded_data = base64.b64decode(base64_data)
        
        # ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
        os.makedirs(temp_dir, exist_ok=True)
        
        # íŒŒì¼ë¡œ ì €ì¥
        file_path = os.path.abspath(os.path.join(temp_dir, output_filename))
        with open(file_path, 'wb') as f:
            f.write(decoded_data)
        
        logger.info(f"âœ… Base64 ì…ë ¥ì„ '{file_path}' íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        return file_path
    except (binascii.Error, ValueError) as e:
        logger.error(f"âŒ Base64 ë””ì½”ë”© ì‹¤íŒ¨: {e}")
        raise Exception(f"Base64 ë””ì½”ë”© ì‹¤íŒ¨: {e}")
    
def queue_prompt(prompt, is_mega_model=False):
    url = f"http://{server_address}:8188/prompt"
    logger.info(f"Queueing prompt to: {url}")
    
    # è°ƒè¯•ï¼šæ£€æŸ¥å…³é”®èŠ‚ç‚¹çš„é…ç½®ï¼ˆå‘é€å‰æœ€åéªŒè¯ï¼‰
    logger.info("å‘é€promptå‰çš„æœ€åéªŒè¯:")
    if is_mega_model:
        # Rapid-AIO-Mega.json éªŒè¯
        if "16" in prompt and "widgets_values" in prompt["16"]:
            image_path_check = prompt["16"]["widgets_values"][0] if prompt["16"]["widgets_values"] else None
            logger.info(f"  èŠ‚ç‚¹16çš„image = {image_path_check}")
        if "28" in prompt and "widgets_values" in prompt["28"]:
            widgets = prompt["28"]["widgets_values"]
            logger.info(f"  èŠ‚ç‚¹28çš„strength = {widgets[3]} (I2V mode)")
    else:
        # æ ‡å‡† workflow éªŒè¯
        if "541" in prompt and "inputs" in prompt["541"]:
            fun_or_fl2v = prompt["541"]["inputs"].get("fun_or_fl2v_model")
            logger.info(f"  èŠ‚ç‚¹541çš„fun_or_fl2v_model = {fun_or_fl2v} (ç±»å‹: {type(fun_or_fl2v).__name__})")
        if "244" in prompt and "inputs" in prompt["244"]:
            image_path_check = prompt["244"]["inputs"].get("image")
            logger.info(f"  èŠ‚ç‚¹244çš„image = {image_path_check}")
    
    p = {"prompt": prompt, "client_id": client_id}
    data = json.dumps(p).encode('utf-8')
    req = urllib.request.Request(url, data=data)
    req.add_header('Content-Type', 'application/json')
    try:
        response = urllib.request.urlopen(req)
        return json.loads(response.read())
    except urllib.error.HTTPError as e:
        error_body = e.read().decode('utf-8')
        logger.error(f"HTTP Error {e.code}: {e.reason}")
        logger.error(f"Error response: {error_body}")
        try:
            error_json = json.loads(error_body)
            logger.error(f"Error details: {json.dumps(error_json, indent=2)}")
        except:
            pass
        raise Exception(f"ComfyUI API é”™è¯¯ ({e.code}): {error_body}")

def get_image(filename, subfolder, folder_type):
    url = f"http://{server_address}:8188/view"
    logger.info(f"Getting image from: {url}")
    data = {"filename": filename, "subfolder": subfolder, "type": folder_type}
    url_values = urllib.parse.urlencode(data)
    with urllib.request.urlopen(f"{url}?{url_values}") as response:
        return response.read()

def get_history(prompt_id):
    url = f"http://{server_address}:8188/history/{prompt_id}"
    logger.info(f"Getting history from: {url}")
    with urllib.request.urlopen(url) as response:
        return json.loads(response.read())

def get_videos(ws, prompt, is_mega_model=False):
    prompt_id = queue_prompt(prompt, is_mega_model)['prompt_id']
    output_videos = {}
    error_info = None
    
    while True:
        out = ws.recv()
        if isinstance(out, str):
            message = json.loads(out)
            if message['type'] == 'executing':
                data = message['data']
                if data['node'] is None and data['prompt_id'] == prompt_id:
                    break
            elif message['type'] == 'execution_error':
                # æ•è·æ‰§è¡Œé”™è¯¯
                error_info = message.get('data', {}).get('error', 'Unknown execution error')
                logger.error(f"Execution error received: {error_info}")
        else:
            continue

    history = get_history(prompt_id)[prompt_id]
    
    # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯ä¿¡æ¯
    if 'error' in history:
        error_info = history['error']
        if isinstance(error_info, dict):
            error_info = error_info.get('message', str(error_info))
        logger.error(f"Error in history: {error_info}")
        raise Exception(f"ComfyUI execution error: {error_info}")
    
    # æ£€æŸ¥ outputs æ˜¯å¦å­˜åœ¨
    if 'outputs' not in history:
        if error_info:
            raise Exception(f"ComfyUI execution error: {error_info}")
        raise Exception("No outputs found in execution history")
    
    for node_id in history['outputs']:
        node_output = history['outputs'][node_id]
        videos_output = []
        # æ”¯æŒå¤šç§è§†é¢‘è¾“å‡ºæ ¼å¼ï¼šgifs (æ ‡å‡† workflow) å’Œ videos (VHS_VideoCombine)
        video_list = None
        if 'gifs' in node_output:
            video_list = node_output['gifs']
        elif 'videos' in node_output:
            video_list = node_output['videos']
        
        if video_list:
            for video in video_list:
                # fullpathë¥¼ ì´ìš©í•˜ì—¬ ì§ì ‘ íŒŒì¼ì„ ì½ê³  base64ë¡œ ì¸ì½”ë”©
                if 'fullpath' in video:
                    with open(video['fullpath'], 'rb') as f:
                        video_data = base64.b64encode(f.read()).decode('utf-8')
                    videos_output.append(video_data)
                elif 'filename' in video:
                    # å¦‚æœæ²¡æœ‰ fullpathï¼Œå°è¯•ä½¿ç”¨ filename å’Œ subfolder
                    subfolder = video.get('subfolder', '')
                    folder_type = video.get('type', 'output')
                    filename = video['filename']
                    try:
                        video_bytes = get_image(filename, subfolder, folder_type)
                        video_data = base64.b64encode(video_bytes).decode('utf-8')
                        videos_output.append(video_data)
                    except Exception as e:
                        logger.warning(f"æ— æ³•è¯»å–è§†é¢‘æ–‡ä»¶ {filename}: {e}")
        output_videos[node_id] = videos_output

    return output_videos

def get_available_models():
    """è·å– ComfyUI ä¸­å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
    try:
        url = f"http://{server_address}:8188/object_info"
        with urllib.request.urlopen(url, timeout=5) as response:
            object_info = json.loads(response.read())
            models = []
            
            # é¦–å…ˆå°è¯• WanVideoModelLoaderï¼ˆç”¨äºæ ‡å‡† workflowï¼‰
            if "WanVideoModelLoader" in object_info:
                loader_info = object_info["WanVideoModelLoader"]
                # å°è¯•ä¸åŒçš„è¿”å›æ ¼å¼
                if "model" in loader_info:
                    wan_models = loader_info["model"]
                elif "input" in loader_info and "required" in loader_info["input"]:
                    if "model" in loader_info["input"]["required"]:
                        wan_models = loader_info["input"]["required"]["model"]
                    else:
                        wan_models = []
                else:
                    wan_models = []
                
                # å¤„ç†åµŒå¥—åˆ—è¡¨çš„æƒ…å†µ
                if wan_models and isinstance(wan_models, list) and len(wan_models) > 0:
                    if isinstance(wan_models[0], list):
                        wan_models = wan_models[0]
                    wan_models = [m for m in wan_models if isinstance(m, str)]
                    models.extend(wan_models)
            
            # åŒæ—¶æ£€æŸ¥ CheckpointLoaderSimpleï¼ˆç”¨äº Rapid-AIO-Mega.jsonï¼‰
            if "CheckpointLoaderSimple" in object_info:
                loader_info = object_info["CheckpointLoaderSimple"]
                checkpoint_models = []
                
                # è°ƒè¯•ï¼šæ‰“å° CheckpointLoaderSimple çš„ç»“æ„
                logger.debug(f"CheckpointLoaderSimple loader_info keys: {list(loader_info.keys())}")
                
                # å°è¯•å¤šç§æ–¹å¼è·å–æ¨¡å‹åˆ—è¡¨
                if "input" in loader_info:
                    if "required" in loader_info["input"]:
                        if "ckpt_name" in loader_info["input"]["required"]:
                            checkpoint_models = loader_info["input"]["required"]["ckpt_name"]
                            logger.debug(f"CheckpointLoaderSimple ckpt_name from required: {checkpoint_models}")
                    # ä¹Ÿæ£€æŸ¥ optional
                    if "optional" in loader_info["input"]:
                        if "ckpt_name" in loader_info["input"]["optional"]:
                            optional_models = loader_info["input"]["optional"]["ckpt_name"]
                            logger.debug(f"CheckpointLoaderSimple ckpt_name from optional: {optional_models}")
                
                # ç›´æ¥æ£€æŸ¥æ˜¯å¦æœ‰ ckpt_name å­—æ®µ
                if "ckpt_name" in loader_info:
                    checkpoint_models = loader_info["ckpt_name"]
                    logger.debug(f"CheckpointLoaderSimple ckpt_name direct: {checkpoint_models}")
                
                # å¤„ç†åµŒå¥—åˆ—è¡¨çš„æƒ…å†µ
                if checkpoint_models and isinstance(checkpoint_models, list) and len(checkpoint_models) > 0:
                    if isinstance(checkpoint_models[0], list):
                        checkpoint_models = checkpoint_models[0]
                    checkpoint_models = [m for m in checkpoint_models if isinstance(m, str)]
                    models.extend(checkpoint_models)
                    logger.info(f"CheckpointLoaderSimple æ‰¾åˆ° {len(checkpoint_models)} ä¸ªæ¨¡å‹: {checkpoint_models}")
                else:
                    logger.warning(f"CheckpointLoaderSimple æ¨¡å‹åˆ—è¡¨ä¸ºç©ºï¼Œå¯èƒ½æ¨¡å‹ä¸åœ¨æ ‡å‡†è·¯å¾„ä¸­")
            
            # å»é‡
            models = list(set(models))
            
            if models:
                logger.info(f"å¯ç”¨æ¨¡å‹åˆ—è¡¨: {models}")
            return models if models else []
    except Exception as e:
        logger.warning(f"è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
        return []

def update_model_in_prompt(prompt, node_id, available_models):
    """æ›´æ–° prompt ä¸­æŒ‡å®šèŠ‚ç‚¹çš„æ¨¡å‹åç§°ï¼Œå¦‚æœæ¨¡å‹ä¸å­˜åœ¨åˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹"""
    if node_id not in prompt:
        return False
    
    node = prompt[node_id]
    if "inputs" not in node or "model" not in node["inputs"]:
        return False
    
    current_model = node["inputs"]["model"]
    logger.info(f"èŠ‚ç‚¹ {node_id} é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹: {current_model}")
    
    # å¦‚æœå½“å‰æ¨¡å‹åœ¨å¯ç”¨åˆ—è¡¨ä¸­ï¼Œä¸éœ€è¦æ›´æ–°
    if current_model in available_models:
        logger.info(f"èŠ‚ç‚¹ {node_id} ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹: {current_model}")
        return False
    
    # ä¼˜å…ˆé€‰æ‹© I2V ç›¸å…³çš„æ¨¡å‹ï¼ˆåŒ…å« I2V å…³é”®å­—ï¼‰
    i2v_models = [m for m in available_models if "I2V" in m.upper() or "i2v" in m.lower()]
    if i2v_models:
        new_model = i2v_models[0]
        logger.info(f"èŠ‚ç‚¹ {node_id} æ¨¡å‹æ›´æ–°: {current_model} -> {new_model} (é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹ä¸åœ¨å¯ç”¨åˆ—è¡¨ä¸­ï¼Œå·²è‡ªåŠ¨æ›¿æ¢ä¸º I2V æ¨¡å‹)")
        node["inputs"]["model"] = new_model
        return True
    
    # å¦‚æœæ²¡æœ‰ I2V æ¨¡å‹ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹
    if available_models:
        new_model = available_models[0]
        logger.info(f"èŠ‚ç‚¹ {node_id} æ¨¡å‹æ›´æ–°: {current_model} -> {new_model} (é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹ä¸åœ¨å¯ç”¨åˆ—è¡¨ä¸­ï¼Œå·²è‡ªåŠ¨æ›¿æ¢ä¸ºç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹)")
        node["inputs"]["model"] = new_model
        return True
    
    return False

def load_workflow(workflow_path):
    """åŠ è½½å¹¶éªŒè¯å·¥ä½œæµJSONæ–‡ä»¶"""
    if not os.path.exists(workflow_path):
        raise FileNotFoundError(f"å·¥ä½œæµæ–‡ä»¶ä¸å­˜åœ¨: {workflow_path}")
    
    file_size = os.path.getsize(workflow_path)
    logger.info(f"åŠ è½½å·¥ä½œæµæ–‡ä»¶: {workflow_path} (å¤§å°: {file_size} å­—èŠ‚)")
    
    if file_size == 0:
        raise ValueError(f"å·¥ä½œæµæ–‡ä»¶ä¸ºç©º: {workflow_path}")
    
    try:
        with open(workflow_path, 'r', encoding='utf-8') as file:
            content = file.read()
            # æ£€æŸ¥æ–‡ä»¶å†…å®¹æ˜¯å¦çœ‹èµ·æ¥åƒJSONï¼ˆä»¥{æˆ–[å¼€å¤´ï¼‰
            content_stripped = content.strip()
            if not content_stripped.startswith(('{', '[')):
                # æ˜¾ç¤ºå‰500ä¸ªå­—ç¬¦ä»¥ä¾¿è°ƒè¯•
                preview = content[:500] if len(content) > 500 else content
                logger.error(f"æ–‡ä»¶å†…å®¹ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚å‰500å­—ç¬¦: {preview}")
                raise ValueError(f"å·¥ä½œæµæ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼: {workflow_path}")
            
            return json.loads(content)
    except json.JSONDecodeError as e:
        # æ˜¾ç¤ºé”™è¯¯ä½ç½®é™„è¿‘çš„å†…å®¹
        with open(workflow_path, 'r', encoding='utf-8') as file:
            lines = file.readlines()
            error_line = e.lineno - 1 if e.lineno > 0 else 0
            start_line = max(0, error_line - 2)
            end_line = min(len(lines), error_line + 3)
            context = ''.join(lines[start_line:end_line])
            logger.error(f"JSONè§£æé”™è¯¯ (è¡Œ {e.lineno}, åˆ— {e.colno}):\n{context}")
        raise ValueError(f"å·¥ä½œæµæ–‡ä»¶JSONæ ¼å¼é”™è¯¯: {workflow_path} - {str(e)}")
    except Exception as e:
        logger.error(f"åŠ è½½å·¥ä½œæµæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {workflow_path} - {str(e)}")
        raise

def ensure_model_in_checkpoints(model_name):
    """ç¡®ä¿æ¨¡å‹æ–‡ä»¶åœ¨ checkpoints ç›®å½•ä¸­ï¼Œå¦‚æœä¸åœ¨åˆ™åˆ›å»ºç¬¦å·é“¾æ¥"""
    model_name = os.path.basename(model_name)  # åªå–æ–‡ä»¶å
    
    # å¯èƒ½çš„æ¨¡å‹è·¯å¾„
    possible_paths = [
        "/ComfyUI/models/diffusion_models/" + model_name,
        "/workspace/models/" + model_name,
        "/ComfyUI/models/checkpoints/" + model_name,
    ]
    
    # ç›®æ ‡è·¯å¾„
    target_path = "/ComfyUI/models/checkpoints/" + model_name
    target_dir = "/ComfyUI/models/checkpoints"
    
    # å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„ç¬¦å·é“¾æ¥æˆ–æ–‡ä»¶
    if os.path.exists(target_path):
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç¬¦å·é“¾æ¥
        if os.path.islink(target_path):
            link_target = os.readlink(target_path)
            if os.path.exists(link_target):
                logger.info(f"æ¨¡å‹æ–‡ä»¶ç¬¦å·é“¾æ¥å·²å­˜åœ¨: {target_path} -> {link_target}")
                return True
            else:
                logger.warning(f"ç¬¦å·é“¾æ¥ç›®æ ‡ä¸å­˜åœ¨ï¼Œå°†é‡æ–°åˆ›å»º: {link_target}")
                os.remove(target_path)
        elif os.path.isfile(target_path):
            logger.info(f"æ¨¡å‹æ–‡ä»¶å·²å­˜åœ¨äº checkpoints ç›®å½•: {target_path}")
            return True
    
    # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
    os.makedirs(target_dir, exist_ok=True)
    
    # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
    source_path = None
    for path in possible_paths:
        if os.path.exists(path):
            source_path = path
            logger.info(f"æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {source_path}")
            break
    
    if source_path:
        try:
            # åˆ›å»ºç¬¦å·é“¾æ¥
            if os.path.exists(target_path):
                os.remove(target_path)  # å¦‚æœå·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
            os.symlink(source_path, target_path)
            logger.info(f"å·²åˆ›å»ºç¬¦å·é“¾æ¥: {target_path} -> {source_path}")
            
            # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œè®©æ–‡ä»¶ç³»ç»ŸåŒæ­¥
            time.sleep(0.5)
            
            # éªŒè¯ç¬¦å·é“¾æ¥æ˜¯å¦åˆ›å»ºæˆåŠŸ
            if os.path.exists(target_path) and os.path.islink(target_path):
                logger.info(f"ç¬¦å·é“¾æ¥éªŒè¯æˆåŠŸ: {target_path}")
                return True
            else:
                logger.warning(f"ç¬¦å·é“¾æ¥åˆ›å»ºåéªŒè¯å¤±è´¥ï¼Œå°è¯•å¤åˆ¶æ–‡ä»¶")
                # å¦‚æœç¬¦å·é“¾æ¥éªŒè¯å¤±è´¥ï¼Œå°è¯•å¤åˆ¶æ–‡ä»¶
                import shutil
                if os.path.exists(target_path):
                    os.remove(target_path)
                shutil.copy2(source_path, target_path)
                logger.info(f"å·²å¤åˆ¶æ¨¡å‹æ–‡ä»¶: {source_path} -> {target_path}")
                return True
        except Exception as e:
            logger.warning(f"åˆ›å»ºç¬¦å·é“¾æ¥å¤±è´¥: {e}ï¼Œå°è¯•å¤åˆ¶æ–‡ä»¶")
            try:
                # å¦‚æœç¬¦å·é“¾æ¥å¤±è´¥ï¼Œå°è¯•å¤åˆ¶æ–‡ä»¶
                import shutil
                if os.path.exists(target_path):
                    os.remove(target_path)
                shutil.copy2(source_path, target_path)
                logger.info(f"å·²å¤åˆ¶æ¨¡å‹æ–‡ä»¶: {source_path} -> {target_path}")
                return True
            except Exception as e2:
                logger.error(f"å¤åˆ¶æ¨¡å‹æ–‡ä»¶ä¹Ÿå¤±è´¥: {e2}")
                return False
    else:
        logger.warning(f"æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {model_name}ï¼Œåœ¨ä»¥ä¸‹è·¯å¾„ä¸­æŸ¥æ‰¾: {possible_paths}")
        return False

def handler(job):
    job_input = job.get("input", {})

    # è®°å½•job_inputï¼Œä½†æ’é™¤base64æ•°æ®ä»¥é¿å…æ—¥å¿—è¿‡é•¿
    log_input = {k: v for k, v in job_input.items() if k not in ["image_base64", "end_image_base64"]}
    if "image_base64" in job_input:
        log_input["image_base64"] = f"<base64 data, length: {len(job_input['image_base64'])}>"
    if "end_image_base64" in job_input:
        log_input["end_image_base64"] = f"<base64 data, length: {len(job_input['end_image_base64'])}>"
    logger.info(f"Received job input: {log_input}")
    task_id = f"task_{uuid.uuid4()}"

    # ì´ë¯¸ì§€ ì…ë ¥ ì²˜ë¦¬ (image_path, image_url, image_base64 ì¤‘ í•˜ë‚˜ë§Œ ì‚¬ìš©)
    image_path = None
    if "image_path" in job_input:
        image_path = process_input(job_input["image_path"], task_id, "input_image.jpg", "path")
    elif "image_url" in job_input:
        image_path = process_input(job_input["image_url"], task_id, "input_image.jpg", "url")
    elif "image_base64" in job_input:
        image_path = process_input(job_input["image_base64"], task_id, "input_image.jpg", "base64")
    else:
        # ê¸°ë³¸ê°’ ì‚¬ìš©
        image_path = "/example_image.png"
        logger.info("ê¸°ë³¸ ì´ë¯¸ì§€ íŒŒì¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤: /example_image.png")

    # ì—”ë“œ ì´ë¯¸ì§€ ì…ë ¥ ì²˜ë¦¬ (end_image_path, end_image_url, end_image_base64 ì¤‘ í•˜ë‚˜ë§Œ ì‚¬ìš©)
    end_image_path_local = None
    if "end_image_path" in job_input:
        end_image_path_local = process_input(job_input["end_image_path"], task_id, "end_image.jpg", "path")
    elif "end_image_url" in job_input:
        end_image_path_local = process_input(job_input["end_image_url"], task_id, "end_image.jpg", "url")
    elif "end_image_base64" in job_input:
        end_image_path_local = process_input(job_input["end_image_base64"], task_id, "end_image.jpg", "base64")
    
    # LoRA ì„¤ì • í™•ì¸ - ë°°ì—´ë¡œ ë°›ì•„ì„œ ì²˜ë¦¬
    lora_pairs = job_input.get("lora_pairs", [])
    
    # ìµœëŒ€ 4ê°œ LoRAê¹Œì§€ ì§€ì›
    lora_count = min(len(lora_pairs), 4)
    if lora_count > len(lora_pairs):
        logger.warning(f"LoRA ê°œìˆ˜ê°€ {len(lora_pairs)}ê°œì…ë‹ˆë‹¤. ìµœëŒ€ 4ê°œê¹Œì§€ë§Œ ì§€ì›ë©ë‹ˆë‹¤. ì²˜ìŒ 4ê°œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        lora_pairs = lora_pairs[:4]
    
    # é¦–å…ˆï¼Œç¡®ä¿ MEGA/AIO æ¨¡å‹æ–‡ä»¶åœ¨ checkpoints ç›®å½•ä¸­ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    # è¿™æ · CheckpointLoaderSimple å°±èƒ½æ‰¾åˆ°æ¨¡å‹
    mega_model_name = "wan2.2-rapid-mega-aio-nsfw-v12.1.safetensors"
    if os.path.exists(f"/ComfyUI/models/diffusion_models/{mega_model_name}"):
        logger.info(f"æ£€æµ‹åˆ° MEGA/AIO æ¨¡å‹æ–‡ä»¶ï¼Œç¡®ä¿å…¶åœ¨ checkpoints ç›®å½•ä¸­")
        if ensure_model_in_checkpoints(mega_model_name):
            # ç­‰å¾… ComfyUI é‡æ–°æ‰«ææ¨¡å‹ç›®å½•ï¼ˆå¦‚æœå®ƒæ”¯æŒåŠ¨æ€æ‰«æï¼‰
            # æ³¨æ„ï¼šComfyUI é€šå¸¸åœ¨å¯åŠ¨æ—¶æ‰«æï¼Œä½†æˆ‘ä»¬å¯ä»¥ç­‰å¾…ä¸€ä¸‹
            logger.info("ç­‰å¾… ComfyUI è¯†åˆ«æ–°æ·»åŠ çš„æ¨¡å‹æ–‡ä»¶...")
            time.sleep(2)  # ç­‰å¾… 2 ç§’è®© ComfyUI æœ‰æœºä¼šé‡æ–°æ‰«æ
    
    # è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼Œç”¨äºæ£€æµ‹ MEGA/AIO æ¨¡å‹
    available_models = get_available_models()
    
    # æ£€æµ‹æ˜¯å¦ä¸º MEGA/AIO æ¨¡å‹ï¼ˆæ”¯æŒ I2V å’Œ T2V çš„ all-in-one æ¨¡å‹ï¼‰
    is_mega_model = False
    if available_models:
        for model_name in available_models:
            model_name_lower = model_name.lower()
            if "mega" in model_name_lower or "aio" in model_name_lower or "all-in-one" in model_name_lower or "allinone" in model_name_lower:
                is_mega_model = True
                mega_model_name = model_name
                logger.info(f"æ£€æµ‹åˆ° MEGA/AIO æ¨¡å‹: {model_name}, å°†ä½¿ç”¨ Rapid-AIO-Mega workflow")
                
                # å†æ¬¡ç¡®ä¿æ¨¡å‹æ–‡ä»¶åœ¨ checkpoints ç›®å½•ä¸­ï¼ˆç”¨äº CheckpointLoaderSimpleï¼‰
                ensure_model_in_checkpoints(model_name)
                break
    
    # ì›Œí¬í”Œë¡œìš° íŒŒì¼ ì„ íƒ
    # MEGA/AIO æ¨¡å‹ä½¿ç”¨ Rapid-AIO-Mega.jsonï¼Œå¦åˆ™ä½¿ç”¨æ ‡å‡† workflow
    if is_mega_model:
        workflow_file = "/Rapid-AIO-Mega.json"
        logger.info(f"Using Rapid-AIO-Mega workflow for MEGA/AIO model")
    else:
        workflow_file = "/new_Wan22_flf2v_api.json" if end_image_path_local else "/new_Wan22_api.json"
        logger.info(f"Using {'FLF2V' if end_image_path_local else 'single'} workflow with {lora_count} LoRA pairs")
    
    workflow_data = load_workflow(workflow_file)
    
    # è½¬æ¢ workflow æ ¼å¼ï¼šå¦‚æœä½¿ç”¨ nodes æ•°ç»„æ ¼å¼ï¼Œè½¬æ¢ä¸ºèŠ‚ç‚¹ ID key æ ¼å¼
    if "nodes" in workflow_data:
        # Rapid-AIO-Mega.json ä½¿ç”¨ nodes æ•°ç»„æ ¼å¼ï¼Œéœ€è¦è½¬æ¢
        prompt = {}
        # é¦–å…ˆå»ºç«‹ link_id åˆ° [node_id, output_index] çš„æ˜ å°„
        links_map = {}
        if "links" in workflow_data:
            for link in workflow_data["links"]:
                # link æ ¼å¼: [link_id, source_node_id, source_output_index, target_node_id, target_input_index, type]
                if len(link) >= 6:
                    link_id = link[0]
                    source_node_id = str(link[1])
                    source_output_index = link[2]
                    target_node_id = str(link[3])
                    target_input_index = link[4]
                    # å­˜å‚¨æ˜ å°„ï¼šlink_id -> [source_node_id, source_output_index]
                    links_map[link_id] = [source_node_id, source_output_index]
        
        for node in workflow_data["nodes"]:
            node_id = str(node["id"])
            # åˆ›å»ºç¬¦åˆ ComfyUI API æ ¼å¼çš„èŠ‚ç‚¹å¯¹è±¡
            converted_node = {}
            # å¤åˆ¶æ‰€æœ‰å­—æ®µ
            for key, value in node.items():
                if key != "id":  # æ’é™¤ id å­—æ®µ
                    if key == "inputs":
                        # è½¬æ¢ inputs æ•°ç»„ä¸º inputs å¯¹è±¡
                        converted_inputs = {}
                        if isinstance(value, list):
                            for input_item in value:
                                if isinstance(input_item, dict) and "name" in input_item:
                                    input_name = input_item["name"]
                                    if "link" in input_item and input_item["link"] is not None:
                                        # å¦‚æœæœ‰ linkï¼Œè½¬æ¢ä¸º [node_id, output_index] æ ¼å¼
                                        link_id = input_item["link"]
                                        if link_id in links_map:
                                            converted_inputs[input_name] = links_map[link_id]
                                        else:
                                            # å¦‚æœæ‰¾ä¸åˆ° linkï¼Œä¿æŒåŸå€¼æˆ–è®¾ä¸º None
                                            converted_inputs[input_name] = None
                                    else:
                                        # å¦‚æœæ²¡æœ‰ linkï¼Œå¯èƒ½æ˜¯å¯é€‰è¾“å…¥ï¼Œä¸è®¾ç½®
                                        pass
                        converted_node["inputs"] = converted_inputs
                    else:
                        converted_node[key] = value
            # å°† type å­—æ®µè½¬æ¢ä¸º class_typeï¼ˆComfyUI API éœ€è¦ï¼‰
            if "type" in converted_node:
                converted_node["class_type"] = converted_node["type"]
                # ä¿ç•™ type å­—æ®µï¼ˆæŸäº›æƒ…å†µä¸‹å¯èƒ½éœ€è¦ï¼‰
            prompt[node_id] = converted_node
        logger.info("å·²è½¬æ¢ nodes æ•°ç»„æ ¼å¼ä¸ºèŠ‚ç‚¹ ID key æ ¼å¼")
    else:
        # new_Wan22_api.json ä½¿ç”¨èŠ‚ç‚¹ ID key æ ¼å¼
        prompt = workflow_data
    
    # æ›´æ–°æ¨¡å‹åç§°ï¼ˆä»…å¯¹æ ‡å‡† workflowï¼‰
    if not is_mega_model and available_models:
        # æ›´æ–°èŠ‚ç‚¹ 122 å’Œ 549 çš„æ¨¡å‹åç§°ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        update_model_in_prompt(prompt, "122", available_models)
        update_model_in_prompt(prompt, "549", available_models)
    elif is_mega_model and available_models:
        # å¯¹äº Rapid-AIO-Mega.jsonï¼Œæ›´æ–°èŠ‚ç‚¹ 26 (CheckpointLoaderSimple) çš„æ¨¡å‹
        if "26" in prompt and "widgets_values" in prompt["26"]:
            current_model = prompt["26"]["widgets_values"][0] if prompt["26"]["widgets_values"] else ""
            # æŸ¥æ‰¾ MEGA/AIO æ¨¡å‹
            mega_models = [m for m in available_models if "mega" in m.lower() or "aio" in m.lower() or "all-in-one" in m.lower() or "allinone" in m.lower()]
            if mega_models:
                new_model = mega_models[0]
                if current_model != new_model:
                    prompt["26"]["widgets_values"][0] = new_model
                    logger.info(f"èŠ‚ç‚¹ 26 æ¨¡å‹æ›´æ–°: {current_model} -> {new_model}")
            elif available_models:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ° MEGA æ¨¡å‹ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹
                new_model = available_models[0]
                if current_model != new_model:
                    prompt["26"]["widgets_values"][0] = new_model
                    logger.info(f"èŠ‚ç‚¹ 26 æ¨¡å‹æ›´æ–°: {current_model} -> {new_model}")
    
    length = job_input.get("length", 81)
    # All-in-one æ¨¡å‹æ¨èä½¿ç”¨ 4 stepsï¼Œä½†ä¿æŒå‘åå…¼å®¹å…è®¸è‡ªå®šä¹‰
    steps = job_input.get("steps", 4)
    seed = job_input.get("seed", 42)
    cfg = job_input.get("cfg", 1.0)
    positive_prompt = job_input.get("prompt", "running man, grab the gun")
    negative_prompt = job_input.get("negative_prompt", "")
    
    # í•´ìƒë„(í­/ë†’ì´) 16ë°°ìˆ˜ ë³´ì •
    original_width = job_input.get("width", 480)
    original_height = job_input.get("height", 832)
    adjusted_width = to_nearest_multiple_of_16(original_width)
    adjusted_height = to_nearest_multiple_of_16(original_height)
    if adjusted_width != original_width:
        logger.info(f"Width adjusted to nearest multiple of 16: {original_width} -> {adjusted_width}")
    if adjusted_height != original_height:
        logger.info(f"Height adjusted to nearest multiple of 16: {original_height} -> {adjusted_height}")
    
    if is_mega_model:
        # Rapid-AIO-Mega.json workflow èŠ‚ç‚¹é…ç½®
        # é¦–å…ˆè®¾ç½® widgets_valuesï¼Œç„¶åç»Ÿä¸€è½¬æ¢ä¸º inputs
        
        # èŠ‚ç‚¹16: LoadImage (èµ·å§‹å›¾åƒ)
        if "16" in prompt:
            if "widgets_values" in prompt["16"]:
                prompt["16"]["widgets_values"][0] = image_path
            # ç¡®ä¿ inputs å­˜åœ¨å¹¶è®¾ç½® image
            if "inputs" not in prompt["16"]:
                prompt["16"]["inputs"] = {}
            prompt["16"]["inputs"]["image"] = image_path
            logger.info(f"èŠ‚ç‚¹16 (èµ·å§‹å›¾åƒ): {image_path}")
        
        # èŠ‚ç‚¹37: LoadImage (ç»“æŸå›¾åƒï¼Œå¯é€‰)
        # å¦‚æœæ²¡æœ‰ç»“æŸå›¾åƒï¼Œéœ€è¦åˆ é™¤èŠ‚ç‚¹37æˆ–æ–­å¼€å…¶è¿æ¥
        if "37" in prompt:
            if end_image_path_local:
                if "widgets_values" in prompt["37"]:
                    prompt["37"]["widgets_values"][0] = end_image_path_local
                if "inputs" not in prompt["37"]:
                    prompt["37"]["inputs"] = {}
                prompt["37"]["inputs"]["image"] = end_image_path_local
                logger.info(f"èŠ‚ç‚¹37 (ç»“æŸå›¾åƒ): {end_image_path_local}")
            else:
                # æ²¡æœ‰ç»“æŸå›¾åƒæ—¶ï¼Œåˆ é™¤èŠ‚ç‚¹37ä»¥é¿å…éªŒè¯é”™è¯¯
                # åŒæ—¶éœ€è¦æ–­å¼€å…¶ä»–èŠ‚ç‚¹å¯¹èŠ‚ç‚¹37çš„å¼•ç”¨
                del prompt["37"]
                logger.info("èŠ‚ç‚¹37 (ç»“æŸå›¾åƒ): å·²åˆ é™¤ï¼ˆæœªæä¾›ç»“æŸå›¾åƒï¼‰")
                
                # æ£€æŸ¥èŠ‚ç‚¹34æ˜¯å¦å¼•ç”¨äº†èŠ‚ç‚¹37ï¼Œå¦‚æœæœ‰åˆ™æ–­å¼€è¿æ¥
                if "34" in prompt and "inputs" in prompt["34"]:
                    # å¦‚æœèŠ‚ç‚¹34çš„ end_image è¾“å…¥å¼•ç”¨äº†èŠ‚ç‚¹37ï¼Œéœ€è¦ç§»é™¤
                    if "end_image" in prompt["34"]["inputs"]:
                        end_image_ref = prompt["34"]["inputs"]["end_image"]
                        if isinstance(end_image_ref, list) and len(end_image_ref) > 0 and str(end_image_ref[0]) == "37":
                            # æ–­å¼€è¿æ¥ï¼Œè®¾ä¸º None æˆ–ç§»é™¤
                            del prompt["34"]["inputs"]["end_image"]
                            logger.info("èŠ‚ç‚¹34: å·²æ–­å¼€ä¸èŠ‚ç‚¹37çš„è¿æ¥ï¼ˆæœªæä¾›ç»“æŸå›¾åƒï¼‰")
        
        # èŠ‚ç‚¹26: CheckpointLoaderSimple - widgets_values[0] æ˜¯æ¨¡å‹åç§°
        if "26" in prompt:
            if "widgets_values" in prompt["26"] and prompt["26"]["widgets_values"]:
                model_name = prompt["26"]["widgets_values"][0]
            else:
                # å¦‚æœæ²¡æœ‰ widgets_valuesï¼Œå°è¯•ä»å¯ç”¨æ¨¡å‹åˆ—è¡¨ä¸­è·å–
                if available_models:
                    model_name = available_models[0]
                else:
                    model_name = "wan2.2-rapid-mega-aio-nsfw-v12.1.safetensors"  # é»˜è®¤å€¼
            
            if "inputs" not in prompt["26"]:
                prompt["26"]["inputs"] = {}
            
            # è·å– CheckpointLoaderSimple çš„å®é™…å¯ç”¨æ¨¡å‹åˆ—è¡¨
            checkpoint_models = []
            try:
                url = f"http://{server_address}:8188/object_info"
                with urllib.request.urlopen(url, timeout=5) as response:
                    object_info = json.loads(response.read())
                    if "CheckpointLoaderSimple" in object_info:
                        loader_info = object_info["CheckpointLoaderSimple"]
                        if "input" in loader_info and "required" in loader_info["input"]:
                            if "ckpt_name" in loader_info["input"]["required"]:
                                checkpoint_models = loader_info["input"]["required"]["ckpt_name"]
                                if isinstance(checkpoint_models, list) and len(checkpoint_models) > 0:
                                    if isinstance(checkpoint_models[0], list):
                                        checkpoint_models = checkpoint_models[0]
                                    checkpoint_models = [m for m in checkpoint_models if isinstance(m, str)]
                        logger.info(f"CheckpointLoaderSimple å¯ç”¨æ¨¡å‹åˆ—è¡¨: {checkpoint_models}")
            except Exception as e:
                logger.warning(f"è·å– CheckpointLoaderSimple æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
            
            # å†³å®šä½¿ç”¨å“ªä¸ªæ¨¡å‹åç§°
            if checkpoint_models:
                # å¦‚æœ CheckpointLoaderSimple æœ‰æ¨¡å‹åˆ—è¡¨
                if model_name in checkpoint_models:
                    # æ¨¡å‹åœ¨åˆ—è¡¨ä¸­ï¼Œä½¿ç”¨å®ƒ
                    final_model_name = model_name
                    logger.info(f"ä½¿ç”¨æ¨¡å‹: {final_model_name} (åœ¨ CheckpointLoaderSimple åˆ—è¡¨ä¸­)")
                else:
                    # æ¨¡å‹ä¸åœ¨åˆ—è¡¨ä¸­ï¼Œä½¿ç”¨åˆ—è¡¨ä¸­çš„ç¬¬ä¸€ä¸ª
                    final_model_name = checkpoint_models[0]
                    logger.warning(f"æ¨¡å‹ '{model_name}' ä¸åœ¨ CheckpointLoaderSimple åˆ—è¡¨ä¸­ï¼Œä½¿ç”¨åˆ—è¡¨ä¸­çš„ç¬¬ä¸€ä¸ª: {final_model_name}")
            else:
                # CheckpointLoaderSimple çš„æ¨¡å‹åˆ—è¡¨ä¸ºç©º
                # å¦‚æœæ¨¡å‹åœ¨ WanVideoModelLoader ä¸­ï¼Œè¯´æ˜æ¨¡å‹å¯èƒ½åœ¨ /workspace/models/ è·¯å¾„
                # CheckpointLoaderSimple å¯èƒ½æ— æ³•è¯†åˆ«ï¼Œä½†æˆ‘ä»¬ä»ç„¶å°è¯•ä½¿ç”¨æ¨¡å‹åç§°
                if model_name in available_models:
                    final_model_name = model_name
                    logger.warning(f"CheckpointLoaderSimple æ¨¡å‹åˆ—è¡¨ä¸ºç©ºï¼Œä½†æ¨¡å‹ '{model_name}' åœ¨ WanVideoModelLoader ä¸­")
                    logger.warning(f"å°è¯•ä½¿ç”¨æ¨¡å‹åç§° '{final_model_name}'ï¼Œå¦‚æœéªŒè¯å¤±è´¥ï¼Œå¯èƒ½éœ€è¦æ£€æŸ¥æ¨¡å‹è·¯å¾„é…ç½®")
                else:
                    # æ¨¡å‹ä¹Ÿä¸åœ¨ WanVideoModelLoader ä¸­ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    final_model_name = model_name
                    logger.warning(f"CheckpointLoaderSimple å’Œ WanVideoModelLoader éƒ½æ— æ³•æ‰¾åˆ°æ¨¡å‹ï¼Œä½¿ç”¨é»˜è®¤åç§°: {final_model_name}")
            
            prompt["26"]["inputs"]["ckpt_name"] = final_model_name
            
            logger.info(f"èŠ‚ç‚¹26 (æ¨¡å‹): {prompt['26']['inputs']['ckpt_name']}")
        
        # èŠ‚ç‚¹48: PrimitiveInt - widgets_values[0] æ˜¯å¸§æ•°
        if "48" in prompt:
            if "widgets_values" in prompt["48"]:
                prompt["48"]["widgets_values"][0] = length
            if "inputs" not in prompt["48"]:
                prompt["48"]["inputs"] = {}
            prompt["48"]["inputs"]["value"] = length
            logger.info(f"èŠ‚ç‚¹48 (å¸§æ•°): {length}")
        
        # èŠ‚ç‚¹34: WanVideoVACEStartToEndFrame - widgets_values[0] æ˜¯ num_frames, widgets_values[1] æ˜¯ empty_frame_level
        if "34" in prompt:
            if "widgets_values" in prompt["34"]:
                prompt["34"]["widgets_values"][0] = length
                # widgets_values[1] æ˜¯ empty_frame_level (é»˜è®¤ 0.5)
                if len(prompt["34"]["widgets_values"]) < 2:
                    prompt["34"]["widgets_values"].append(0.5)
            if "inputs" not in prompt["34"]:
                prompt["34"]["inputs"] = {}
            prompt["34"]["inputs"]["num_frames"] = length
            prompt["34"]["inputs"]["empty_frame_level"] = prompt["34"]["widgets_values"][1] if len(prompt["34"]["widgets_values"]) > 1 else 0.5
            logger.info(f"èŠ‚ç‚¹34 (VACE num_frames): {length}, empty_frame_level: {prompt['34']['inputs']['empty_frame_level']}")
        
        # èŠ‚ç‚¹28: WanVaceToVideo - widgets_values[0]=width, [1]=height, [2]=length, [3]=strength, [4]=batch_size
        if "28" in prompt:
            if "widgets_values" in prompt["28"]:
                prompt["28"]["widgets_values"][0] = adjusted_width
                prompt["28"]["widgets_values"][1] = adjusted_height
                prompt["28"]["widgets_values"][2] = length
                prompt["28"]["widgets_values"][3] = 1  # strength = 1 for I2V
                if len(prompt["28"]["widgets_values"]) < 5:
                    prompt["28"]["widgets_values"].append(1)  # batch_size
            if "inputs" not in prompt["28"]:
                prompt["28"]["inputs"] = {}
            prompt["28"]["inputs"]["width"] = adjusted_width
            prompt["28"]["inputs"]["height"] = adjusted_height
            prompt["28"]["inputs"]["batch_size"] = prompt["28"]["widgets_values"][4] if len(prompt["28"]["widgets_values"]) > 4 else 1
            prompt["28"]["inputs"]["strength"] = 1  # I2V mode
            logger.info(f"èŠ‚ç‚¹28 (WanVaceToVideo): width={adjusted_width}, height={adjusted_height}, batch_size={prompt['28']['inputs']['batch_size']}, strength=1 (I2V)")
        
        # èŠ‚ç‚¹9: CLIPTextEncode (æ­£é¢æç¤ºè¯)
        if "9" in prompt:
            if "widgets_values" in prompt["9"]:
                prompt["9"]["widgets_values"][0] = positive_prompt
            if "inputs" not in prompt["9"]:
                prompt["9"]["inputs"] = {}
            prompt["9"]["inputs"]["text"] = positive_prompt
            logger.info(f"èŠ‚ç‚¹9 (æ­£é¢æç¤ºè¯): {positive_prompt}")
        
        # èŠ‚ç‚¹10: CLIPTextEncode (è´Ÿé¢æç¤ºè¯)
        if "10" in prompt:
            if "widgets_values" in prompt["10"]:
                prompt["10"]["widgets_values"][0] = negative_prompt
            if "inputs" not in prompt["10"]:
                prompt["10"]["inputs"] = {}
            prompt["10"]["inputs"]["text"] = negative_prompt
            logger.info(f"èŠ‚ç‚¹10 (è´Ÿé¢æç¤ºè¯): {negative_prompt}")
        
        # èŠ‚ç‚¹32: ModelSamplingSD3 - widgets_values[0] æ˜¯ shift
        if "32" in prompt:
            if "widgets_values" in prompt["32"]:
                shift_value = prompt["32"]["widgets_values"][0]
            else:
                shift_value = 8  # é»˜è®¤å€¼
            if "inputs" not in prompt["32"]:
                prompt["32"]["inputs"] = {}
            prompt["32"]["inputs"]["shift"] = shift_value
            logger.info(f"èŠ‚ç‚¹32 (ModelSamplingSD3): shift={shift_value}")
        
        # èŠ‚ç‚¹8: KSampler - widgets_values[0]=seed, [1]=control_after_generate, [2]=steps, [3]=cfg, [4]=sampler_name, [5]=scheduler, [6]=denoise
        if "8" in prompt:
            if "widgets_values" in prompt["8"]:
                widgets = prompt["8"]["widgets_values"]
                prompt["8"]["widgets_values"][0] = seed
                prompt["8"]["widgets_values"][2] = steps
                prompt["8"]["widgets_values"][3] = cfg
            if "inputs" not in prompt["8"]:
                prompt["8"]["inputs"] = {}
            widgets = prompt["8"].get("widgets_values", [seed, "fixed", steps, cfg, "ipndm", "beta", 1])
            prompt["8"]["inputs"]["seed"] = seed
            prompt["8"]["inputs"]["steps"] = steps
            prompt["8"]["inputs"]["cfg"] = cfg
            prompt["8"]["inputs"]["sampler_name"] = widgets[4] if len(widgets) > 4 else "ipndm"
            prompt["8"]["inputs"]["scheduler"] = widgets[5] if len(widgets) > 5 else "beta"
            prompt["8"]["inputs"]["denoise"] = widgets[6] if len(widgets) > 6 else 1.0
            logger.info(f"èŠ‚ç‚¹8 (KSampler): seed={seed}, steps={steps}, cfg={cfg}, sampler={prompt['8']['inputs']['sampler_name']}, scheduler={prompt['8']['inputs']['scheduler']}, denoise={prompt['8']['inputs']['denoise']}")
        
        # èŠ‚ç‚¹39: VHS_VideoCombine - éœ€è¦å°† widgets_values è½¬æ¢ä¸º inputs
        if "39" in prompt:
            # ç¡®ä¿ inputs å­˜åœ¨
            if "inputs" not in prompt["39"]:
                prompt["39"]["inputs"] = {}
            
            # å¦‚æœå­˜åœ¨ widgets_valuesï¼Œå°†å…¶è½¬æ¢ä¸º inputs
            if "widgets_values" in prompt["39"]:
                widgets = prompt["39"]["widgets_values"]
                # VHS_VideoCombine éœ€è¦çš„å‚æ•°
                if isinstance(widgets, dict):
                    # å°† widgets_values å­—å…¸ä¸­çš„å‚æ•°å¤åˆ¶åˆ° inputs
                    for key, value in widgets.items():
                        if key not in ["videopreview"]:  # æ’é™¤ä¸éœ€è¦çš„å‚æ•°
                            prompt["39"]["inputs"][key] = value
                    logger.info(f"èŠ‚ç‚¹39 (VHS_VideoCombine): å·²ä» widgets_values è½¬æ¢å‚æ•°åˆ° inputs")
                else:
                    # å¦‚æœ widgets_values æ˜¯æ•°ç»„ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    prompt["39"]["inputs"]["frame_rate"] = 16
                    prompt["39"]["inputs"]["loop_count"] = 0
                    prompt["39"]["inputs"]["filename_prefix"] = "rapid-mega-out/vid"
                    prompt["39"]["inputs"]["format"] = "video/h264-mp4"
                    prompt["39"]["inputs"]["save_output"] = True
                    prompt["39"]["inputs"]["pingpong"] = False
                    logger.info(f"èŠ‚ç‚¹39 (VHS_VideoCombine): ä½¿ç”¨é»˜è®¤å‚æ•°")
            else:
                # å¦‚æœæ²¡æœ‰ widgets_valuesï¼Œä½¿ç”¨é»˜è®¤å€¼
                prompt["39"]["inputs"]["frame_rate"] = 16
                prompt["39"]["inputs"]["loop_count"] = 0
                prompt["39"]["inputs"]["filename_prefix"] = "rapid-mega-out/vid"
                prompt["39"]["inputs"]["format"] = "video/h264-mp4"
                prompt["39"]["inputs"]["save_output"] = True
                prompt["39"]["inputs"]["pingpong"] = False
                logger.info(f"èŠ‚ç‚¹39 (VHS_VideoCombine): ä½¿ç”¨é»˜è®¤å‚æ•°")
    else:
        # æ ‡å‡† workflow (new_Wan22_api.json) èŠ‚ç‚¹é…ç½®
        prompt["244"]["inputs"]["image"] = image_path
        prompt["541"]["inputs"]["num_frames"] = length
        # å½“æœ‰è¾“å…¥å›¾åƒæ—¶ï¼Œå¿…é¡»è®¾ç½® fun_or_fl2v_model ä¸º true ä»¥æ”¯æŒ I2V æ¨¡å¼
        if image_path and "541" in prompt and "inputs" in prompt["541"]:
            # å¼ºåˆ¶è®¾ç½®ä¸ºå¸ƒå°”å€¼ Trueï¼Œç¡®ä¿JSONåºåˆ—åŒ–æ­£ç¡®
            prompt["541"]["inputs"]["fun_or_fl2v_model"] = True
            # éªŒè¯è®¾ç½®æ˜¯å¦æˆåŠŸ
            actual_value = prompt["541"]["inputs"].get("fun_or_fl2v_model")
            logger.info(f"å·²è®¾ç½® fun_or_fl2v_model = {actual_value} (ç±»å‹: {type(actual_value).__name__}) ä»¥æ”¯æŒ I2V æ¨¡å¼")
        prompt["135"]["inputs"]["positive_prompt"] = positive_prompt
        prompt["220"]["inputs"]["seed"] = seed
        prompt["540"]["inputs"]["seed"] = seed
        prompt["540"]["inputs"]["cfg"] = cfg
        prompt["235"]["inputs"]["value"] = adjusted_width
        prompt["236"]["inputs"]["value"] = adjusted_height
    
    if not is_mega_model:
        # æ ‡å‡† workflow çš„ context_overlap å’Œ steps è®¾ç½®
        # context_overlap åŠ¨æ€è°ƒæ•´ï¼šç¡®ä¿ä¸è¶…è¿‡æ€»å¸§æ•°ï¼Œä¸”å¯¹çŸ­è§†é¢‘ä½¿ç”¨æ›´ä¿å®ˆçš„å€¼
        user_overlap = job_input.get("context_overlap")
        if user_overlap is not None:
            # ç”¨æˆ·æŒ‡å®šäº†å€¼ï¼Œä½†éœ€è¦ç¡®ä¿ä¸è¶…è¿‡æ€»å¸§æ•°
            context_overlap = min(user_overlap, length - 1) if length > 1 else 0
            if user_overlap != context_overlap:
                logger.warning(f"context_overlap {user_overlap} exceeds length {length}, adjusted to {context_overlap}")
        else:
            # è‡ªåŠ¨è®¡ç®—ï¼šå¯¹äºçŸ­è§†é¢‘ä½¿ç”¨æ›´å°çš„å€¼
            if length < 50:
                # çŸ­è§†é¢‘ï¼šæœ€å¤š 30% æˆ– 12ï¼Œå–è¾ƒå°å€¼
                context_overlap = min(12, max(1, int(length * 0.3)))
            else:
                # é•¿è§†é¢‘ï¼šæœ€å¤š 60% æˆ– 48ï¼Œå–è¾ƒå°å€¼
                context_overlap = min(48, max(12, int(length * 0.6)))
            logger.info(f"Auto-calculated context_overlap: {context_overlap} for length: {length}")
        
        if "498" in prompt:
            prompt["498"]["inputs"]["context_overlap"] = context_overlap
        
        # step ì„¤ì • ì ìš©
        if "834" in prompt:
            prompt["834"]["inputs"]["steps"] = steps
            logger.info(f"Steps set to: {steps}")
            lowsteps = int(steps*0.6)
            if "829" in prompt:
                prompt["829"]["inputs"]["step"] = lowsteps
                logger.info(f"LowSteps set to: {lowsteps}")

        # ì—”ë“œ ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²½ìš° 617ë²ˆ ë…¸ë“œì— ê²½ë¡œ ì ìš© (FLF2V ì „ìš©)
        if end_image_path_local and "617" in prompt:
            prompt["617"]["inputs"]["image"] = end_image_path_local
    
    # LoRA ì„¤ì • ì ìš©
    if lora_count > 0:
        if is_mega_model:
            # Rapid-AIO-Mega.json å¯èƒ½ä¸æ”¯æŒ LoRAï¼Œè®°å½•è­¦å‘Š
            logger.warning(f"Rapid-AIO-Mega workflow ä¸æ”¯æŒ LoRA è®¾ç½®ï¼Œå·²å¿½ç•¥ {lora_count} ä¸ª LoRA pairs")
        else:
            # æ ‡å‡† workflow çš„ LoRA è®¾ç½® - HIGH LoRAëŠ” ë…¸ë“œ 279, LOW LoRAëŠ” ë…¸ë“œ 553
            high_lora_node_id = "279"
            low_lora_node_id = "553"
            
            # ì…ë ¥ë°›ì€ LoRA pairs ì ìš© (lora_1ë¶€í„° ì‹œì‘)
            for i, lora_pair in enumerate(lora_pairs):
                if i < 4:  # ìµœëŒ€ 4ê°œê¹Œì§€ë§Œ
                    lora_high = lora_pair.get("high")
                    lora_low = lora_pair.get("low")
                    lora_high_weight = lora_pair.get("high_weight", 1.0)
                    lora_low_weight = lora_pair.get("low_weight", 1.0)
                    
                    # HIGH LoRA ì„¤ì • (ë…¸ë“œ 279ë²ˆ, lora_0ë¶€í„° ì‹œì‘)
                    if lora_high and high_lora_node_id in prompt:
                        prompt[high_lora_node_id]["inputs"][f"lora_{i}"] = lora_high
                        prompt[high_lora_node_id]["inputs"][f"strength_{i}"] = lora_high_weight
                        logger.info(f"LoRA {i+1} HIGH applied to node 279: {lora_high} with weight {lora_high_weight}")
                    
                    # LOW LoRA ì„¤ì • (ë…¸ë“œ 553ë²ˆ, lora_0ë¶€í„° ì‹œì‘)
                    if lora_low and low_lora_node_id in prompt:
                        prompt[low_lora_node_id]["inputs"][f"lora_{i}"] = lora_low
                        prompt[low_lora_node_id]["inputs"][f"strength_{i}"] = lora_low_weight
                        logger.info(f"LoRA {i+1} LOW applied to node 553: {lora_low} with weight {lora_low_weight}")

    # éªŒè¯å…³é”®å‚æ•°è®¾ç½® - æ— æ¡ä»¶è¾“å‡ºéªŒè¯ä¿¡æ¯
    logger.info("=" * 60)
    logger.info("éªŒè¯å…³é”®èŠ‚ç‚¹é…ç½®:")
    
    if is_mega_model:
        # Rapid-AIO-Mega.json éªŒè¯
        if "16" in prompt and "widgets_values" in prompt["16"]:
            image_in_16 = prompt["16"]["widgets_values"][0] if prompt["16"]["widgets_values"] else None
            logger.info(f"âœ“ èŠ‚ç‚¹16 (èµ·å§‹å›¾åƒ): {image_in_16}")
        if "28" in prompt and "widgets_values" in prompt["28"]:
            widgets = prompt["28"]["widgets_values"]
            logger.info(f"âœ“ èŠ‚ç‚¹28 (WanVaceToVideo): width={widgets[0]}, height={widgets[1]}, length={widgets[2]}, strength={widgets[3]} (I2V)")
        if "34" in prompt and "widgets_values" in prompt["34"]:
            num_frames_34 = prompt["34"]["widgets_values"][0] if prompt["34"]["widgets_values"] else None
            logger.info(f"âœ“ èŠ‚ç‚¹34 (VACE num_frames): {num_frames_34}")
        if "8" in prompt and "widgets_values" in prompt["8"]:
            widgets = prompt["8"]["widgets_values"]
            logger.info(f"âœ“ èŠ‚ç‚¹8 (KSampler): seed={widgets[0]}, steps={widgets[2]}, cfg={widgets[3]}")
        if "39" in prompt:
            if "inputs" in prompt["39"]:
                inputs_39 = prompt["39"]["inputs"]
                images_input = inputs_39.get("images")
                logger.info(f"âœ“ èŠ‚ç‚¹39 (VHS_VideoCombine): images={images_input}, frame_rate={inputs_39.get('frame_rate')}, format={inputs_39.get('format')}")
            else:
                logger.warning("âœ— èŠ‚ç‚¹39 ç¼ºå°‘ inputs")
    else:
        # æ ‡å‡† workflow éªŒè¯
        if "244" in prompt:
            if "inputs" in prompt["244"]:
                image_in_244 = prompt["244"]["inputs"].get("image")
                logger.info(f"âœ“ èŠ‚ç‚¹244 (LoadImage): image = {image_in_244}")
            else:
                logger.warning("âœ— èŠ‚ç‚¹244 ç¼ºå°‘ inputs")
        else:
            logger.warning("âœ— èŠ‚ç‚¹244 ä¸å­˜åœ¨")
        
        if "541" in prompt:
            if "inputs" in prompt["541"]:
                fun_or_fl2v_value = prompt["541"]["inputs"].get("fun_or_fl2v_model")
                logger.info(f"âœ“ èŠ‚ç‚¹541 (WanVideoImageToVideoEncode): fun_or_fl2v_model = {fun_or_fl2v_value} (ç±»å‹: {type(fun_or_fl2v_value).__name__})")
                if fun_or_fl2v_value != True:
                    logger.warning(f"âš  è­¦å‘Š: fun_or_fl2v_model ä¸æ˜¯ Trueï¼Œå®é™…å€¼: {fun_or_fl2v_value}")
                
                num_frames = prompt["541"]["inputs"].get("num_frames")
                logger.info(f"  - num_frames = {num_frames}")
            else:
                logger.warning("âœ— èŠ‚ç‚¹541 ç¼ºå°‘ inputs")
        else:
            logger.warning("âœ— èŠ‚ç‚¹541 ä¸å­˜åœ¨")
    
    logger.info("=" * 60)
    
    ws_url = f"ws://{server_address}:8188/ws?clientId={client_id}"
    logger.info(f"Connecting to WebSocket: {ws_url}")
    
    # ë¨¼ì € HTTP ì—°ê²°ì´ ê°€ëŠ¥í•œì§€ í™•ì¸
    http_url = f"http://{server_address}:8188/"
    logger.info(f"Checking HTTP connection to: {http_url}")
    
    # HTTP ì—°ê²° í™•ì¸ (ìµœëŒ€ 1ë¶„)
    max_http_attempts = 180
    for http_attempt in range(max_http_attempts):
        try:
            import urllib.request
            response = urllib.request.urlopen(http_url, timeout=5)
            logger.info(f"HTTP ì—°ê²° ì„±ê³µ (ì‹œë„ {http_attempt+1})")
            break
        except Exception as e:
            logger.warning(f"HTTP ì—°ê²° ì‹¤íŒ¨ (ì‹œë„ {http_attempt+1}/{max_http_attempts}): {e}")
            if http_attempt == max_http_attempts - 1:
                raise Exception("ComfyUI ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
            time.sleep(1)
    
    ws = websocket.WebSocket()
    # ì›¹ì†Œì¼“ ì—°ê²° ì‹œë„ (ìµœëŒ€ 3ë¶„)
    max_attempts = int(180/5)  # 3ë¶„ (1ì´ˆì— í•œ ë²ˆì”© ì‹œë„)
    for attempt in range(max_attempts):
        try:
            ws.connect(ws_url)
            logger.info(f"ì›¹ì†Œì¼“ ì—°ê²° ì„±ê³µ (ì‹œë„ {attempt+1})")
            break
        except Exception as e:
            logger.warning(f"ì›¹ì†Œì¼“ ì—°ê²° ì‹¤íŒ¨ (ì‹œë„ {attempt+1}/{max_attempts}): {e}")
            if attempt == max_attempts - 1:
                raise Exception("ì›¹ì†Œì¼“ ì—°ê²° ì‹œê°„ ì´ˆê³¼ (3ë¶„)")
            time.sleep(5)
    try:
        videos = get_videos(ws, prompt, is_mega_model)
        ws.close()

        # ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
        for node_id in videos:
            if videos[node_id]:
                return {"video": videos[node_id][0]}
        
        return {"error": "ë¹„ë””ì˜¤ë¥¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
    except Exception as e:
        ws.close()
        error_message = str(e)
        logger.error(f"Video generation failed: {error_message}")
        return {"error": error_message}

if __name__ == "__main__":
    runpod.serverless.start({"handler": handler})